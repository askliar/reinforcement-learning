{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "LCWg5Lw0Bhp_",
        "QR2Bc5z6BhqR",
        "OimCXVQ-Bhqw",
        "Pl5Su__lBhq8",
        "-vURScBlBhrL",
        "OZVXY8JgBhre"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/askliar/reinforcement-learning/blob/master/labs/lab2/lab2_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "2fpU5Z1MBhpP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Parts of this assignment will be **automatically graded**. Please take note of the following:\n",
        "- Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
        "- You can add additional cells, but it is not recommended to (re)move cells. Cells required for autograding cannot be moved and cells containing tests cannot be edited.\n",
        "- You are allowed to use a service such as [Google Colaboratory](https://colab.research.google.com/) to work together. However, you **cannot** hand in the notebook that was hosted on Google Colaboratory, but you need to copy your answers into the original notebook and verify that it runs succesfully offline. This is because Google Colaboratory destroys the metadata required for grading.\n",
        "- Name your notebook **exactly** `{TA_name}_{student1_id}_{student2_id}_lab{i}.ipynb`, for example `wouter_12345_67890_lab1.ipynb` (or elise or stephan, depending on your TA), **otherwise your submission will be skipped by our regex and you will get 0 points** (but no penalty as we cannot parse your student ids ;)).\n",
        "\n",
        "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your names below:"
      ]
    },
    {
      "metadata": {
        "id": "nwo33uG6BhpS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NAMES = \"Andrii Skliar, Gabriele Bani\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "toAUFvhmBhpa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---"
      ]
    },
    {
      "metadata": {
        "id": "RPLAbs8YEXym",
        "colab_type": "code",
        "outputId": "b66fa19d-5231-4c81-8c1a-3e08fb44103c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16153
        }
      },
      "cell_type": "code",
      "source": [
        "### ONLY FOR COLAB\n",
        "!apt-get install -y cmake\n",
        "!apt-get install -y python-numpy python-dev zlib1g-dev libjpeg-dev xvfb libav-tools xorg-dev python-opengl libboost-all-dev libsdl2-dev swig\n",
        "!apt-get install ffmpeg\n",
        "!apt-get install xvfb\n",
        "!apt-get install python-opengl\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install piglet\n",
        "!pip install gym\n",
        "!pip install pyopengl\n",
        "\n",
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch\n",
        "\n",
        "# Start virtual display\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1024, 768))\n",
        "display.start()\n",
        "import os\n",
        "os.environ[\"DISPLAY\"] = \":\" + str(display.display) + \".\" + str(display.screen)\n",
        "\n",
        "###"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  cmake-data libarchive13 libjsoncpp1 liblzo2-2 librhash0 libuv1\n",
            "Suggested packages:\n",
            "  cmake-doc ninja-build lrzip\n",
            "The following NEW packages will be installed:\n",
            "  cmake cmake-data libarchive13 libjsoncpp1 liblzo2-2 librhash0 libuv1\n",
            "0 upgraded, 7 newly installed, 0 to remove and 5 not upgraded.\n",
            "Need to get 5,023 kB of archives.\n",
            "After this operation, 25.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 liblzo2-2 amd64 2.08-1.2 [48.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 cmake-data all 3.10.2-1ubuntu2 [1,331 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libarchive13 amd64 3.2.2-3.1ubuntu0.1 [289 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjsoncpp1 amd64 1.7.4-3 [73.6 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 librhash0 amd64 1.3.6-2 [78.1 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libuv1 amd64 1.18.0-3 [64.4 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 cmake amd64 3.10.2-1ubuntu2 [3,138 kB]\n",
            "Fetched 5,023 kB in 0s (30.2 MB/s)\n",
            "Selecting previously unselected package liblzo2-2:amd64.\n",
            "(Reading database ... 22298 files and directories currently installed.)\n",
            "Preparing to unpack .../0-liblzo2-2_2.08-1.2_amd64.deb ...\n",
            "Unpacking liblzo2-2:amd64 (2.08-1.2) ...\n",
            "Selecting previously unselected package cmake-data.\n",
            "Preparing to unpack .../1-cmake-data_3.10.2-1ubuntu2_all.deb ...\n",
            "Unpacking cmake-data (3.10.2-1ubuntu2) ...\n",
            "Selecting previously unselected package libarchive13:amd64.\n",
            "Preparing to unpack .../2-libarchive13_3.2.2-3.1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libarchive13:amd64 (3.2.2-3.1ubuntu0.1) ...\n",
            "Selecting previously unselected package libjsoncpp1:amd64.\n",
            "Preparing to unpack .../3-libjsoncpp1_1.7.4-3_amd64.deb ...\n",
            "Unpacking libjsoncpp1:amd64 (1.7.4-3) ...\n",
            "Selecting previously unselected package librhash0:amd64.\n",
            "Preparing to unpack .../4-librhash0_1.3.6-2_amd64.deb ...\n",
            "Unpacking librhash0:amd64 (1.3.6-2) ...\n",
            "Selecting previously unselected package libuv1:amd64.\n",
            "Preparing to unpack .../5-libuv1_1.18.0-3_amd64.deb ...\n",
            "Unpacking libuv1:amd64 (1.18.0-3) ...\n",
            "Selecting previously unselected package cmake.\n",
            "Preparing to unpack .../6-cmake_3.10.2-1ubuntu2_amd64.deb ...\n",
            "Unpacking cmake (3.10.2-1ubuntu2) ...\n",
            "Setting up libuv1:amd64 (1.18.0-3) ...\n",
            "Setting up cmake-data (3.10.2-1ubuntu2) ...\n",
            "Setting up librhash0:amd64 (1.3.6-2) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Setting up liblzo2-2:amd64 (2.08-1.2) ...\n",
            "Setting up libjsoncpp1:amd64 (1.7.4-3) ...\n",
            "Setting up libarchive13:amd64 (3.2.2-3.1ubuntu0.1) ...\n",
            "Setting up cmake (3.10.2-1ubuntu2) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Package libav-tools is not available, but is referred to by another package.\n",
            "This may mean that the package is missing, has been obsoleted, or\n",
            "is only available from another source\n",
            "However the following packages replace it:\n",
            "  ffmpeg\n",
            "\n",
            "E: Package 'libav-tools' has no installation candidate\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fontconfig i965-va-driver libaacs0 libasound2 libasound2-data libass9\n",
            "  libasyncns0 libavc1394-0 libavcodec57 libavdevice57 libavfilter6\n",
            "  libavformat57 libavresample3 libavutil55 libbdplus0 libbluray2 libbs2b0\n",
            "  libcaca0 libcairo2 libcdio-cdda2 libcdio-paranoia2 libcdio17 libchromaprint1\n",
            "  libcroco3 libcrystalhd3 libdatrie1 libdc1394-22 libdrm-amdgpu1 libdrm-intel1\n",
            "  libdrm-nouveau2 libdrm-radeon1 libfftw3-double3 libflac8 libflite1\n",
            "  libfribidi0 libgdk-pixbuf2.0-0 libgdk-pixbuf2.0-bin libgdk-pixbuf2.0-common\n",
            "  libgl1 libgl1-mesa-dri libglx-mesa0 libglx0 libgme0 libgsm1 libiec61883-0\n",
            "  libjack-jackd2-0 libjbig0 libllvm6.0 libmp3lame0 libmpg123-0 libmysofa0\n",
            "  libnuma1 libogg0 libopenal-data libopenal1 libopenjp2-7 libopenmpt0 libopus0\n",
            "  libpango-1.0-0 libpangocairo-1.0-0 libpangoft2-1.0-0 libpciaccess0\n",
            "  libpixman-1-0 libpostproc54 libpulse0 libraw1394-11 librsvg2-2\n",
            "  librsvg2-common librubberband2 libsamplerate0 libsdl2-2.0-0 libsensors4\n",
            "  libshine3 libslang2 libsnappy1v5 libsndfile1 libsndio6.1 libsoxr0 libspeex1\n",
            "  libssh-gcrypt-4 libswresample2 libswscale4 libthai-data libthai0 libtheora0\n",
            "  libtiff5 libtwolame0 libusb-1.0-0 libva-drm2 libva-x11-2 libva2 libvdpau1\n",
            "  libvorbis0a libvorbisenc2 libvorbisfile3 libvpx5 libwavpack1\n",
            "  libwayland-cursor0 libwayland-egl1-mesa libwebp6 libwebpmux3 libwrap0\n",
            "  libx264-152 libx265-146 libxcb-glx0 libxcb-render0 libxcb-shape0 libxcb-shm0\n",
            "  libxcursor1 libxdamage1 libxfixes3 libxi6 libxinerama1 libxkbcommon0\n",
            "  libxrandr2 libxv1 libxvidcore4 libxxf86vm1 libzvbi-common libzvbi0\n",
            "  mesa-va-drivers mesa-vdpau-drivers shared-mime-info va-driver-all\n",
            "  vdpau-driver-all xkb-data\n",
            "Suggested packages:\n",
            "  ffmpeg-doc i965-va-driver-shaders libasound2-plugins alsa-utils\n",
            "  libbluray-bdj firmware-crystalhd libfftw3-bin libfftw3-dev jackd2\n",
            "  libportaudio2 opus-tools pciutils pulseaudio libraw1394-doc librsvg2-bin\n",
            "  lm-sensors sndiod speex libvdpau-va-gl1 nvidia-vdpau-driver\n",
            "  nvidia-legacy-340xx-vdpau-driver\n",
            "The following NEW packages will be installed:\n",
            "  ffmpeg fontconfig i965-va-driver libaacs0 libasound2 libasound2-data libass9\n",
            "  libasyncns0 libavc1394-0 libavcodec57 libavdevice57 libavfilter6\n",
            "  libavformat57 libavresample3 libavutil55 libbdplus0 libbluray2 libbs2b0\n",
            "  libcaca0 libcairo2 libcdio-cdda2 libcdio-paranoia2 libcdio17 libchromaprint1\n",
            "  libcroco3 libcrystalhd3 libdatrie1 libdc1394-22 libdrm-amdgpu1 libdrm-intel1\n",
            "  libdrm-nouveau2 libdrm-radeon1 libfftw3-double3 libflac8 libflite1\n",
            "  libfribidi0 libgdk-pixbuf2.0-0 libgdk-pixbuf2.0-bin libgdk-pixbuf2.0-common\n",
            "  libgl1 libgl1-mesa-dri libglx-mesa0 libglx0 libgme0 libgsm1 libiec61883-0\n",
            "  libjack-jackd2-0 libjbig0 libllvm6.0 libmp3lame0 libmpg123-0 libmysofa0\n",
            "  libnuma1 libogg0 libopenal-data libopenal1 libopenjp2-7 libopenmpt0 libopus0\n",
            "  libpango-1.0-0 libpangocairo-1.0-0 libpangoft2-1.0-0 libpciaccess0\n",
            "  libpixman-1-0 libpostproc54 libpulse0 libraw1394-11 librsvg2-2\n",
            "  librsvg2-common librubberband2 libsamplerate0 libsdl2-2.0-0 libsensors4\n",
            "  libshine3 libslang2 libsnappy1v5 libsndfile1 libsndio6.1 libsoxr0 libspeex1\n",
            "  libssh-gcrypt-4 libswresample2 libswscale4 libthai-data libthai0 libtheora0\n",
            "  libtiff5 libtwolame0 libusb-1.0-0 libva-drm2 libva-x11-2 libva2 libvdpau1\n",
            "  libvorbis0a libvorbisenc2 libvorbisfile3 libvpx5 libwavpack1\n",
            "  libwayland-cursor0 libwayland-egl1-mesa libwebp6 libwebpmux3 libwrap0\n",
            "  libx264-152 libx265-146 libxcb-glx0 libxcb-render0 libxcb-shape0 libxcb-shm0\n",
            "  libxcursor1 libxdamage1 libxfixes3 libxi6 libxinerama1 libxkbcommon0\n",
            "  libxrandr2 libxv1 libxvidcore4 libxxf86vm1 libzvbi-common libzvbi0\n",
            "  mesa-va-drivers mesa-vdpau-drivers shared-mime-info va-driver-all\n",
            "  vdpau-driver-all xkb-data\n",
            "0 upgraded, 127 newly installed, 0 to remove and 5 not upgraded.\n",
            "Need to get 60.5 MB of archives.\n",
            "After this operation, 355 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 fontconfig amd64 2.12.6-0ubuntu2 [169 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libogg0 amd64 1.3.2-1 [17.2 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxinerama1 amd64 2:1.1.3-1 [7,908 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86vm1 amd64 1:1.1.4-1 [10.6 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfribidi0 amd64 0.19.7-2 [24.9 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libslang2 amd64 2.3.1a-3ubuntu1 [424 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 shared-mime-info amd64 1.9-2 [426 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 xkb-data all 2.23.1-1ubuntu1 [325 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libnuma1 amd64 2.0.11-2.1 [21.6 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libusb-1.0-0 amd64 2:1.0.21-2 [43.3 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libva2 amd64 2.1.0-3 [47.6 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libva-drm2 amd64 2.1.0-3 [6,880 B]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxfixes3 amd64 1:5.0.3-1 [10.8 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libva-x11-2 amd64 2.1.0-3 [11.5 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libvdpau1 amd64 1.1.1-3ubuntu1 [25.5 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libavutil55 amd64 7:3.4.4-0ubuntu0.18.04.1 [190 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpixman-1-0 amd64 0.34.0-2 [229 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcb-render0 amd64 1.13-1 [14.7 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcb-shm0 amd64 1.13-1 [5,572 B]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcairo2 amd64 1.15.10-2 [580 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libcrystalhd3 amd64 1:0.0~git20110715.fdd2f19-12 [45.8 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgsm1 amd64 1.0.13-4build1 [22.4 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmp3lame0 amd64 3.100-2 [136 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopenjp2-7 amd64 2.3.0-1 [145 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic/main amd64 libopus0 amd64 1.1.2-1ubuntu1 [159 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcroco3 amd64 0.6.12-2 [81.3 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjbig0 amd64 2.1-3.1build1 [26.7 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtiff5 amd64 4.0.9-5 [152 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgdk-pixbuf2.0-common all 2.36.11-2 [4,536 B]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgdk-pixbuf2.0-0 amd64 2.36.11-2 [165 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu bionic/main amd64 libthai-data all 0.1.27-2 [133 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdatrie1 amd64 0.2.10-7 [17.8 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu bionic/main amd64 libthai0 amd64 0.1.27-2 [18.0 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpango-1.0-0 amd64 1.40.14-1ubuntu0.1 [153 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpangoft2-1.0-0 amd64 1.40.14-1ubuntu0.1 [33.2 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpangocairo-1.0-0 amd64 1.40.14-1ubuntu0.1 [20.8 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu bionic/main amd64 librsvg2-2 amd64 2.40.20-2 [98.6 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libshine3 amd64 3.1.1-1 [22.9 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsnappy1v5 amd64 1.1.7-1 [16.0 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu bionic/main amd64 libspeex1 amd64 1.2~rc1.2-1ubuntu2 [52.1 kB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsoxr0 amd64 0.1.2-3 [65.9 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libswresample2 amd64 7:3.4.4-0ubuntu0.18.04.1 [55.2 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtheora0 amd64 1.1.1+dfsg.1-14 [170 kB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtwolame0 amd64 0.3.13-3 [46.7 kB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu bionic/main amd64 libvorbis0a amd64 1.3.5-4.2 [86.4 kB]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu bionic/main amd64 libvorbisenc2 amd64 1.3.5-4.2 [70.7 kB]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu bionic/main amd64 libvpx5 amd64 1.7.0-3 [798 kB]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libwavpack1 amd64 5.1.0-2ubuntu1.1 [76.6 kB]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu bionic/main amd64 libwebp6 amd64 0.6.1-2 [185 kB]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu bionic/main amd64 libwebpmux3 amd64 0.6.1-2 [19.6 kB]\n",
            "Get:51 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libx264-152 amd64 2:0.152.2854+gite9a5903-2 [609 kB]\n",
            "Get:52 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libx265-146 amd64 2.6-3 [1,026 kB]\n",
            "Get:53 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libxvidcore4 amd64 2:1.3.5-1 [200 kB]\n",
            "Get:54 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libzvbi-common all 0.2.35-13 [32.1 kB]\n",
            "Get:55 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libzvbi0 amd64 0.2.35-13 [235 kB]\n",
            "Get:56 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libavcodec57 amd64 7:3.4.4-0ubuntu0.18.04.1 [4,592 kB]\n",
            "Get:57 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libasound2-data all 1.1.3-5ubuntu0.1 [36.3 kB]\n",
            "Get:58 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libasound2 amd64 1.1.3-5ubuntu0.1 [359 kB]\n",
            "Get:59 http://archive.ubuntu.com/ubuntu bionic/main amd64 libraw1394-11 amd64 2.1.2-1 [30.7 kB]\n",
            "Get:60 http://archive.ubuntu.com/ubuntu bionic/main amd64 libavc1394-0 amd64 0.5.4-4build1 [16.1 kB]\n",
            "Get:61 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libass9 amd64 1:0.14.0-1 [88.2 kB]\n",
            "Get:62 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libbluray2 amd64 1:1.0.2-3 [141 kB]\n",
            "Get:63 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libchromaprint1 amd64 1.4.3-1 [36.8 kB]\n",
            "Get:64 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgme0 amd64 0.6.2-1 [121 kB]\n",
            "Get:65 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmpg123-0 amd64 1.25.10-1 [125 kB]\n",
            "Get:66 http://archive.ubuntu.com/ubuntu bionic/main amd64 libvorbisfile3 amd64 1.3.5-4.2 [16.0 kB]\n",
            "Get:67 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopenmpt0 amd64 0.3.6-1 [561 kB]\n",
            "Get:68 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libssh-gcrypt-4 amd64 0.8.0~20170825.94fa1e38-1ubuntu0.1 [171 kB]\n",
            "Get:69 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libavformat57 amd64 7:3.4.4-0ubuntu0.18.04.1 [949 kB]\n",
            "Get:70 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libavresample3 amd64 7:3.4.4-0ubuntu0.18.04.1 [52.6 kB]\n",
            "Get:71 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libbs2b0 amd64 3.1.0+dfsg-2.2 [10.5 kB]\n",
            "Get:72 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libflite1 amd64 2.1-release-1 [12.8 MB]\n",
            "Get:73 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmysofa0 amd64 0.6~dfsg0-2 [37.8 kB]\n",
            "Get:74 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libpostproc54 amd64 7:3.4.4-0ubuntu0.18.04.1 [50.4 kB]\n",
            "Get:75 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfftw3-double3 amd64 3.3.7-1 [735 kB]\n",
            "Get:76 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsamplerate0 amd64 0.1.9-1 [938 kB]\n",
            "Get:77 http://archive.ubuntu.com/ubuntu bionic/universe amd64 librubberband2 amd64 1.8.1-7ubuntu2 [86.7 kB]\n",
            "Get:78 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libswscale4 amd64 7:3.4.4-0ubuntu0.18.04.1 [150 kB]\n",
            "Get:79 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libavfilter6 amd64 7:3.4.4-0ubuntu0.18.04.1 [874 kB]\n",
            "Get:80 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcaca0 amd64 0.99.beta19-2build2~gcc5.3 [202 kB]\n",
            "Get:81 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcdio17 amd64 1.0.0-2ubuntu2 [58.8 kB]\n",
            "Get:82 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcdio-cdda2 amd64 10.2+0.94+2-2build1 [17.7 kB]\n",
            "Get:83 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcdio-paranoia2 amd64 10.2+0.94+2-2build1 [17.2 kB]\n",
            "Get:84 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libdc1394-22 amd64 2.2.5-1 [77.5 kB]\n",
            "Get:85 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcb-glx0 amd64 1.13-1 [22.0 kB]\n",
            "Get:86 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxdamage1 amd64 1:1.1.4-3 [6,934 B]\n",
            "Get:87 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdrm-amdgpu1 amd64 2.4.91-2 [19.0 kB]\n",
            "Get:88 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpciaccess0 amd64 0.14-1 [17.9 kB]\n",
            "Get:89 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdrm-intel1 amd64 2.4.91-2 [59.8 kB]\n",
            "Get:90 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdrm-nouveau2 amd64 2.4.91-2 [16.5 kB]\n",
            "Get:91 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdrm-radeon1 amd64 2.4.91-2 [21.7 kB]\n",
            "Get:92 http://archive.ubuntu.com/ubuntu bionic/main amd64 libllvm6.0 amd64 1:6.0-1ubuntu2 [14.5 MB]\n",
            "Get:93 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsensors4 amd64 1:3.4.0-4 [28.8 kB]\n",
            "Get:94 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgl1-mesa-dri amd64 18.0.5-0ubuntu0~18.04.1 [6,011 kB]\n",
            "Get:95 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libglx-mesa0 amd64 18.0.5-0ubuntu0~18.04.1 [132 kB]\n",
            "Get:96 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libglx0 amd64 1.0.0-2ubuntu2.2 [28.1 kB]\n",
            "Get:97 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgl1 amd64 1.0.0-2ubuntu2.2 [84.8 kB]\n",
            "Get:98 http://archive.ubuntu.com/ubuntu bionic/main amd64 libiec61883-0 amd64 1.2.0-2 [23.5 kB]\n",
            "Get:99 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjack-jackd2-0 amd64 1.9.12~dfsg-2 [263 kB]\n",
            "Get:100 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopenal-data all 1:1.18.2-2 [102 kB]\n",
            "Get:101 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsndio6.1 amd64 1.1.0-3 [23.4 kB]\n",
            "Get:102 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopenal1 amd64 1:1.18.2-2 [266 kB]\n",
            "Get:103 http://archive.ubuntu.com/ubuntu bionic/main amd64 libasyncns0 amd64 0.8-6 [12.1 kB]\n",
            "Get:104 http://archive.ubuntu.com/ubuntu bionic/main amd64 libflac8 amd64 1.3.2-1 [213 kB]\n",
            "Get:105 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsndfile1 amd64 1.0.28-4 [169 kB]\n",
            "Get:106 http://archive.ubuntu.com/ubuntu bionic/main amd64 libwrap0 amd64 7.6.q-27 [46.3 kB]\n",
            "Get:107 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpulse0 amd64 1:11.1-1ubuntu7.1 [265 kB]\n",
            "Get:108 http://archive.ubuntu.com/ubuntu bionic/main amd64 libwayland-cursor0 amd64 1.14.0-2 [9,976 B]\n",
            "Get:109 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libwayland-egl1-mesa amd64 18.0.5-0ubuntu0~18.04.1 [7,148 B]\n",
            "Get:110 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcursor1 amd64 1:1.1.15-1 [19.8 kB]\n",
            "Get:111 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxi6 amd64 2:1.7.9-1 [29.2 kB]\n",
            "Get:112 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxkbcommon0 amd64 0.8.0-1ubuntu0.1 [97.9 kB]\n",
            "Get:113 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxrandr2 amd64 2:1.5.1-1 [18.1 kB]\n",
            "Get:114 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libsdl2-2.0-0 amd64 2.0.8+dfsg1-1ubuntu1.18.04.1 [378 kB]\n",
            "Get:115 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcb-shape0 amd64 1.13-1 [5,964 B]\n",
            "Get:116 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxv1 amd64 2:1.0.11-1 [10.7 kB]\n",
            "Get:117 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libavdevice57 amd64 7:3.4.4-0ubuntu0.18.04.1 [74.9 kB]\n",
            "Get:118 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 ffmpeg amd64 7:3.4.4-0ubuntu0.18.04.1 [1,587 kB]\n",
            "Get:119 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libaacs0 amd64 0.9.0-1 [51.4 kB]\n",
            "Get:120 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libbdplus0 amd64 0.1.2-2 [46.6 kB]\n",
            "Get:121 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgdk-pixbuf2.0-bin amd64 2.36.11-2 [7,864 B]\n",
            "Get:122 http://archive.ubuntu.com/ubuntu bionic/main amd64 librsvg2-common amd64 2.40.20-2 [5,124 B]\n",
            "Get:123 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 mesa-va-drivers amd64 18.0.5-0ubuntu0~18.04.1 [1,778 kB]\n",
            "Get:124 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 mesa-vdpau-drivers amd64 18.0.5-0ubuntu0~18.04.1 [1,902 kB]\n",
            "Get:125 http://archive.ubuntu.com/ubuntu bionic/universe amd64 i965-va-driver amd64 2.1.0-0ubuntu1 [925 kB]\n",
            "Get:126 http://archive.ubuntu.com/ubuntu bionic/universe amd64 va-driver-all amd64 2.1.0-3 [4,376 B]\n",
            "Get:127 http://archive.ubuntu.com/ubuntu bionic/main amd64 vdpau-driver-all amd64 1.1.1-3ubuntu1 [4,674 B]\n",
            "Fetched 60.5 MB in 1s (53.6 MB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Selecting previously unselected package fontconfig.\n",
            "(Reading database ... 24714 files and directories currently installed.)\n",
            "Preparing to unpack .../000-fontconfig_2.12.6-0ubuntu2_amd64.deb ...\n",
            "Unpacking fontconfig (2.12.6-0ubuntu2) ...\n",
            "Selecting previously unselected package libogg0:amd64.\n",
            "Preparing to unpack .../001-libogg0_1.3.2-1_amd64.deb ...\n",
            "Unpacking libogg0:amd64 (1.3.2-1) ...\n",
            "Selecting previously unselected package libxinerama1:amd64.\n",
            "Preparing to unpack .../002-libxinerama1_2%3a1.1.3-1_amd64.deb ...\n",
            "Unpacking libxinerama1:amd64 (2:1.1.3-1) ...\n",
            "Selecting previously unselected package libxxf86vm1:amd64.\n",
            "Preparing to unpack .../003-libxxf86vm1_1%3a1.1.4-1_amd64.deb ...\n",
            "Unpacking libxxf86vm1:amd64 (1:1.1.4-1) ...\n",
            "Selecting previously unselected package libfribidi0:amd64.\n",
            "Preparing to unpack .../004-libfribidi0_0.19.7-2_amd64.deb ...\n",
            "Unpacking libfribidi0:amd64 (0.19.7-2) ...\n",
            "Selecting previously unselected package libslang2:amd64.\n",
            "Preparing to unpack .../005-libslang2_2.3.1a-3ubuntu1_amd64.deb ...\n",
            "Unpacking libslang2:amd64 (2.3.1a-3ubuntu1) ...\n",
            "Selecting previously unselected package shared-mime-info.\n",
            "Preparing to unpack .../006-shared-mime-info_1.9-2_amd64.deb ...\n",
            "Unpacking shared-mime-info (1.9-2) ...\n",
            "Selecting previously unselected package xkb-data.\n",
            "Preparing to unpack .../007-xkb-data_2.23.1-1ubuntu1_all.deb ...\n",
            "Unpacking xkb-data (2.23.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnuma1:amd64.\n",
            "Preparing to unpack .../008-libnuma1_2.0.11-2.1_amd64.deb ...\n",
            "Unpacking libnuma1:amd64 (2.0.11-2.1) ...\n",
            "Selecting previously unselected package libusb-1.0-0:amd64.\n",
            "Preparing to unpack .../009-libusb-1.0-0_2%3a1.0.21-2_amd64.deb ...\n",
            "Unpacking libusb-1.0-0:amd64 (2:1.0.21-2) ...\n",
            "Selecting previously unselected package libva2:amd64.\n",
            "Preparing to unpack .../010-libva2_2.1.0-3_amd64.deb ...\n",
            "Unpacking libva2:amd64 (2.1.0-3) ...\n",
            "Selecting previously unselected package libva-drm2:amd64.\n",
            "Preparing to unpack .../011-libva-drm2_2.1.0-3_amd64.deb ...\n",
            "Unpacking libva-drm2:amd64 (2.1.0-3) ...\n",
            "Selecting previously unselected package libxfixes3:amd64.\n",
            "Preparing to unpack .../012-libxfixes3_1%3a5.0.3-1_amd64.deb ...\n",
            "Unpacking libxfixes3:amd64 (1:5.0.3-1) ...\n",
            "Selecting previously unselected package libva-x11-2:amd64.\n",
            "Preparing to unpack .../013-libva-x11-2_2.1.0-3_amd64.deb ...\n",
            "Unpacking libva-x11-2:amd64 (2.1.0-3) ...\n",
            "Selecting previously unselected package libvdpau1:amd64.\n",
            "Preparing to unpack .../014-libvdpau1_1.1.1-3ubuntu1_amd64.deb ...\n",
            "Unpacking libvdpau1:amd64 (1.1.1-3ubuntu1) ...\n",
            "Selecting previously unselected package libavutil55:amd64.\n",
            "Preparing to unpack .../015-libavutil55_7%3a3.4.4-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libavutil55:amd64 (7:3.4.4-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libpixman-1-0:amd64.\n",
            "Preparing to unpack .../016-libpixman-1-0_0.34.0-2_amd64.deb ...\n",
            "Unpacking libpixman-1-0:amd64 (0.34.0-2) ...\n",
            "Selecting previously unselected package libxcb-render0:amd64.\n",
            "Preparing to unpack .../017-libxcb-render0_1.13-1_amd64.deb ...\n",
            "Unpacking libxcb-render0:amd64 (1.13-1) ...\n",
            "Selecting previously unselected package libxcb-shm0:amd64.\n",
            "Preparing to unpack .../018-libxcb-shm0_1.13-1_amd64.deb ...\n",
            "Unpacking libxcb-shm0:amd64 (1.13-1) ...\n",
            "Selecting previously unselected package libcairo2:amd64.\n",
            "Preparing to unpack .../019-libcairo2_1.15.10-2_amd64.deb ...\n",
            "Unpacking libcairo2:amd64 (1.15.10-2) ...\n",
            "Selecting previously unselected package libcrystalhd3:amd64.\n",
            "Preparing to unpack .../020-libcrystalhd3_1%3a0.0~git20110715.fdd2f19-12_amd64.deb ...\n",
            "Unpacking libcrystalhd3:amd64 (1:0.0~git20110715.fdd2f19-12) ...\n",
            "Selecting previously unselected package libgsm1:amd64.\n",
            "Preparing to unpack .../021-libgsm1_1.0.13-4build1_amd64.deb ...\n",
            "Unpacking libgsm1:amd64 (1.0.13-4build1) ...\n",
            "Selecting previously unselected package libmp3lame0:amd64.\n",
            "Preparing to unpack .../022-libmp3lame0_3.100-2_amd64.deb ...\n",
            "Unpacking libmp3lame0:amd64 (3.100-2) ...\n",
            "Selecting previously unselected package libopenjp2-7:amd64.\n",
            "Preparing to unpack .../023-libopenjp2-7_2.3.0-1_amd64.deb ...\n",
            "Unpacking libopenjp2-7:amd64 (2.3.0-1) ...\n",
            "Selecting previously unselected package libopus0:amd64.\n",
            "Preparing to unpack .../024-libopus0_1.1.2-1ubuntu1_amd64.deb ...\n",
            "Unpacking libopus0:amd64 (1.1.2-1ubuntu1) ...\n",
            "Selecting previously unselected package libcroco3:amd64.\n",
            "Preparing to unpack .../025-libcroco3_0.6.12-2_amd64.deb ...\n",
            "Unpacking libcroco3:amd64 (0.6.12-2) ...\n",
            "Selecting previously unselected package libjbig0:amd64.\n",
            "Preparing to unpack .../026-libjbig0_2.1-3.1build1_amd64.deb ...\n",
            "Unpacking libjbig0:amd64 (2.1-3.1build1) ...\n",
            "Selecting previously unselected package libtiff5:amd64.\n",
            "Preparing to unpack .../027-libtiff5_4.0.9-5_amd64.deb ...\n",
            "Unpacking libtiff5:amd64 (4.0.9-5) ...\n",
            "Selecting previously unselected package libgdk-pixbuf2.0-common.\n",
            "Preparing to unpack .../028-libgdk-pixbuf2.0-common_2.36.11-2_all.deb ...\n",
            "Unpacking libgdk-pixbuf2.0-common (2.36.11-2) ...\n",
            "Selecting previously unselected package libgdk-pixbuf2.0-0:amd64.\n",
            "Preparing to unpack .../029-libgdk-pixbuf2.0-0_2.36.11-2_amd64.deb ...\n",
            "Unpacking libgdk-pixbuf2.0-0:amd64 (2.36.11-2) ...\n",
            "Selecting previously unselected package libthai-data.\n",
            "Preparing to unpack .../030-libthai-data_0.1.27-2_all.deb ...\n",
            "Unpacking libthai-data (0.1.27-2) ...\n",
            "Selecting previously unselected package libdatrie1:amd64.\n",
            "Preparing to unpack .../031-libdatrie1_0.2.10-7_amd64.deb ...\n",
            "Unpacking libdatrie1:amd64 (0.2.10-7) ...\n",
            "Selecting previously unselected package libthai0:amd64.\n",
            "Preparing to unpack .../032-libthai0_0.1.27-2_amd64.deb ...\n",
            "Unpacking libthai0:amd64 (0.1.27-2) ...\n",
            "Selecting previously unselected package libpango-1.0-0:amd64.\n",
            "Preparing to unpack .../033-libpango-1.0-0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libpango-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libpangoft2-1.0-0:amd64.\n",
            "Preparing to unpack .../034-libpangoft2-1.0-0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libpangoft2-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libpangocairo-1.0-0:amd64.\n",
            "Preparing to unpack .../035-libpangocairo-1.0-0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libpangocairo-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Selecting previously unselected package librsvg2-2:amd64.\n",
            "Preparing to unpack .../036-librsvg2-2_2.40.20-2_amd64.deb ...\n",
            "Unpacking librsvg2-2:amd64 (2.40.20-2) ...\n",
            "Selecting previously unselected package libshine3:amd64.\n",
            "Preparing to unpack .../037-libshine3_3.1.1-1_amd64.deb ...\n",
            "Unpacking libshine3:amd64 (3.1.1-1) ...\n",
            "Selecting previously unselected package libsnappy1v5:amd64.\n",
            "Preparing to unpack .../038-libsnappy1v5_1.1.7-1_amd64.deb ...\n",
            "Unpacking libsnappy1v5:amd64 (1.1.7-1) ...\n",
            "Selecting previously unselected package libspeex1:amd64.\n",
            "Preparing to unpack .../039-libspeex1_1.2~rc1.2-1ubuntu2_amd64.deb ...\n",
            "Unpacking libspeex1:amd64 (1.2~rc1.2-1ubuntu2) ...\n",
            "Selecting previously unselected package libsoxr0:amd64.\n",
            "Preparing to unpack .../040-libsoxr0_0.1.2-3_amd64.deb ...\n",
            "Unpacking libsoxr0:amd64 (0.1.2-3) ...\n",
            "Selecting previously unselected package libswresample2:amd64.\n",
            "Preparing to unpack .../041-libswresample2_7%3a3.4.4-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libswresample2:amd64 (7:3.4.4-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libtheora0:amd64.\n",
            "Preparing to unpack .../042-libtheora0_1.1.1+dfsg.1-14_amd64.deb ...\n",
            "Unpacking libtheora0:amd64 (1.1.1+dfsg.1-14) ...\n",
            "Selecting previously unselected package libtwolame0:amd64.\n",
            "Preparing to unpack .../043-libtwolame0_0.3.13-3_amd64.deb ...\n",
            "Unpacking libtwolame0:amd64 (0.3.13-3) ...\n",
            "Selecting previously unselected package libvorbis0a:amd64.\n",
            "Preparing to unpack .../044-libvorbis0a_1.3.5-4.2_amd64.deb ...\n",
            "Unpacking libvorbis0a:amd64 (1.3.5-4.2) ...\n",
            "Selecting previously unselected package libvorbisenc2:amd64.\n",
            "Preparing to unpack .../045-libvorbisenc2_1.3.5-4.2_amd64.deb ...\n",
            "Unpacking libvorbisenc2:amd64 (1.3.5-4.2) ...\n",
            "Selecting previously unselected package libvpx5:amd64.\n",
            "Preparing to unpack .../046-libvpx5_1.7.0-3_amd64.deb ...\n",
            "Unpacking libvpx5:amd64 (1.7.0-3) ...\n",
            "Selecting previously unselected package libwavpack1:amd64.\n",
            "Preparing to unpack .../047-libwavpack1_5.1.0-2ubuntu1.1_amd64.deb ...\n",
            "Unpacking libwavpack1:amd64 (5.1.0-2ubuntu1.1) ...\n",
            "Selecting previously unselected package libwebp6:amd64.\n",
            "Preparing to unpack .../048-libwebp6_0.6.1-2_amd64.deb ...\n",
            "Unpacking libwebp6:amd64 (0.6.1-2) ...\n",
            "Selecting previously unselected package libwebpmux3:amd64.\n",
            "Preparing to unpack .../049-libwebpmux3_0.6.1-2_amd64.deb ...\n",
            "Unpacking libwebpmux3:amd64 (0.6.1-2) ...\n",
            "Selecting previously unselected package libx264-152:amd64.\n",
            "Preparing to unpack .../050-libx264-152_2%3a0.152.2854+gite9a5903-2_amd64.deb ...\n",
            "Unpacking libx264-152:amd64 (2:0.152.2854+gite9a5903-2) ...\n",
            "Selecting previously unselected package libx265-146:amd64.\n",
            "Preparing to unpack .../051-libx265-146_2.6-3_amd64.deb ...\n",
            "Unpacking libx265-146:amd64 (2.6-3) ...\n",
            "Selecting previously unselected package libxvidcore4:amd64.\n",
            "Preparing to unpack .../052-libxvidcore4_2%3a1.3.5-1_amd64.deb ...\n",
            "Unpacking libxvidcore4:amd64 (2:1.3.5-1) ...\n",
            "Selecting previously unselected package libzvbi-common.\n",
            "Preparing to unpack .../053-libzvbi-common_0.2.35-13_all.deb ...\n",
            "Unpacking libzvbi-common (0.2.35-13) ...\n",
            "Selecting previously unselected package libzvbi0:amd64.\n",
            "Preparing to unpack .../054-libzvbi0_0.2.35-13_amd64.deb ...\n",
            "Unpacking libzvbi0:amd64 (0.2.35-13) ...\n",
            "Selecting previously unselected package libavcodec57:amd64.\n",
            "Preparing to unpack .../055-libavcodec57_7%3a3.4.4-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libavcodec57:amd64 (7:3.4.4-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libasound2-data.\n",
            "Preparing to unpack .../056-libasound2-data_1.1.3-5ubuntu0.1_all.deb ...\n",
            "Unpacking libasound2-data (1.1.3-5ubuntu0.1) ...\n",
            "Selecting previously unselected package libasound2:amd64.\n",
            "Preparing to unpack .../057-libasound2_1.1.3-5ubuntu0.1_amd64.deb ...\n",
            "Unpacking libasound2:amd64 (1.1.3-5ubuntu0.1) ...\n",
            "Selecting previously unselected package libraw1394-11:amd64.\n",
            "Preparing to unpack .../058-libraw1394-11_2.1.2-1_amd64.deb ...\n",
            "Unpacking libraw1394-11:amd64 (2.1.2-1) ...\n",
            "Selecting previously unselected package libavc1394-0:amd64.\n",
            "Preparing to unpack .../059-libavc1394-0_0.5.4-4build1_amd64.deb ...\n",
            "Unpacking libavc1394-0:amd64 (0.5.4-4build1) ...\n",
            "Selecting previously unselected package libass9:amd64.\n",
            "Preparing to unpack .../060-libass9_1%3a0.14.0-1_amd64.deb ...\n",
            "Unpacking libass9:amd64 (1:0.14.0-1) ...\n",
            "Selecting previously unselected package libbluray2:amd64.\n",
            "Preparing to unpack .../061-libbluray2_1%3a1.0.2-3_amd64.deb ...\n",
            "Unpacking libbluray2:amd64 (1:1.0.2-3) ...\n",
            "Selecting previously unselected package libchromaprint1:amd64.\n",
            "Preparing to unpack .../062-libchromaprint1_1.4.3-1_amd64.deb ...\n",
            "Unpacking libchromaprint1:amd64 (1.4.3-1) ...\n",
            "Selecting previously unselected package libgme0:amd64.\n",
            "Preparing to unpack .../063-libgme0_0.6.2-1_amd64.deb ...\n",
            "Unpacking libgme0:amd64 (0.6.2-1) ...\n",
            "Selecting previously unselected package libmpg123-0:amd64.\n",
            "Preparing to unpack .../064-libmpg123-0_1.25.10-1_amd64.deb ...\n",
            "Unpacking libmpg123-0:amd64 (1.25.10-1) ...\n",
            "Selecting previously unselected package libvorbisfile3:amd64.\n",
            "Preparing to unpack .../065-libvorbisfile3_1.3.5-4.2_amd64.deb ...\n",
            "Unpacking libvorbisfile3:amd64 (1.3.5-4.2) ...\n",
            "Selecting previously unselected package libopenmpt0:amd64.\n",
            "Preparing to unpack .../066-libopenmpt0_0.3.6-1_amd64.deb ...\n",
            "Unpacking libopenmpt0:amd64 (0.3.6-1) ...\n",
            "Selecting previously unselected package libssh-gcrypt-4:amd64.\n",
            "Preparing to unpack .../067-libssh-gcrypt-4_0.8.0~20170825.94fa1e38-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libssh-gcrypt-4:amd64 (0.8.0~20170825.94fa1e38-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libavformat57:amd64.\n",
            "Preparing to unpack .../068-libavformat57_7%3a3.4.4-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libavformat57:amd64 (7:3.4.4-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libavresample3:amd64.\n",
            "Preparing to unpack .../069-libavresample3_7%3a3.4.4-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libavresample3:amd64 (7:3.4.4-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libbs2b0:amd64.\n",
            "Preparing to unpack .../070-libbs2b0_3.1.0+dfsg-2.2_amd64.deb ...\n",
            "Unpacking libbs2b0:amd64 (3.1.0+dfsg-2.2) ...\n",
            "Selecting previously unselected package libflite1:amd64.\n",
            "Preparing to unpack .../071-libflite1_2.1-release-1_amd64.deb ...\n",
            "Unpacking libflite1:amd64 (2.1-release-1) ...\n",
            "Selecting previously unselected package libmysofa0:amd64.\n",
            "Preparing to unpack .../072-libmysofa0_0.6~dfsg0-2_amd64.deb ...\n",
            "Unpacking libmysofa0:amd64 (0.6~dfsg0-2) ...\n",
            "Selecting previously unselected package libpostproc54:amd64.\n",
            "Preparing to unpack .../073-libpostproc54_7%3a3.4.4-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libpostproc54:amd64 (7:3.4.4-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libfftw3-double3:amd64.\n",
            "Preparing to unpack .../074-libfftw3-double3_3.3.7-1_amd64.deb ...\n",
            "Unpacking libfftw3-double3:amd64 (3.3.7-1) ...\n",
            "Selecting previously unselected package libsamplerate0:amd64.\n",
            "Preparing to unpack .../075-libsamplerate0_0.1.9-1_amd64.deb ...\n",
            "Unpacking libsamplerate0:amd64 (0.1.9-1) ...\n",
            "Selecting previously unselected package librubberband2:amd64.\n",
            "Preparing to unpack .../076-librubberband2_1.8.1-7ubuntu2_amd64.deb ...\n",
            "Unpacking librubberband2:amd64 (1.8.1-7ubuntu2) ...\n",
            "Selecting previously unselected package libswscale4:amd64.\n",
            "Preparing to unpack .../077-libswscale4_7%3a3.4.4-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libswscale4:amd64 (7:3.4.4-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libavfilter6:amd64.\n",
            "Preparing to unpack .../078-libavfilter6_7%3a3.4.4-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libavfilter6:amd64 (7:3.4.4-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libcaca0:amd64.\n",
            "Preparing to unpack .../079-libcaca0_0.99.beta19-2build2~gcc5.3_amd64.deb ...\n",
            "Unpacking libcaca0:amd64 (0.99.beta19-2build2~gcc5.3) ...\n",
            "Selecting previously unselected package libcdio17:amd64.\n",
            "Preparing to unpack .../080-libcdio17_1.0.0-2ubuntu2_amd64.deb ...\n",
            "Unpacking libcdio17:amd64 (1.0.0-2ubuntu2) ...\n",
            "Selecting previously unselected package libcdio-cdda2:amd64.\n",
            "Preparing to unpack .../081-libcdio-cdda2_10.2+0.94+2-2build1_amd64.deb ...\n",
            "Unpacking libcdio-cdda2:amd64 (10.2+0.94+2-2build1) ...\n",
            "Selecting previously unselected package libcdio-paranoia2:amd64.\n",
            "Preparing to unpack .../082-libcdio-paranoia2_10.2+0.94+2-2build1_amd64.deb ...\n",
            "Unpacking libcdio-paranoia2:amd64 (10.2+0.94+2-2build1) ...\n",
            "Selecting previously unselected package libdc1394-22:amd64.\n",
            "Preparing to unpack .../083-libdc1394-22_2.2.5-1_amd64.deb ...\n",
            "Unpacking libdc1394-22:amd64 (2.2.5-1) ...\n",
            "Selecting previously unselected package libxcb-glx0:amd64.\n",
            "Preparing to unpack .../084-libxcb-glx0_1.13-1_amd64.deb ...\n",
            "Unpacking libxcb-glx0:amd64 (1.13-1) ...\n",
            "Selecting previously unselected package libxdamage1:amd64.\n",
            "Preparing to unpack .../085-libxdamage1_1%3a1.1.4-3_amd64.deb ...\n",
            "Unpacking libxdamage1:amd64 (1:1.1.4-3) ...\n",
            "Selecting previously unselected package libdrm-amdgpu1:amd64.\n",
            "Preparing to unpack .../086-libdrm-amdgpu1_2.4.91-2_amd64.deb ...\n",
            "Unpacking libdrm-amdgpu1:amd64 (2.4.91-2) ...\n",
            "Selecting previously unselected package libpciaccess0:amd64.\n",
            "Preparing to unpack .../087-libpciaccess0_0.14-1_amd64.deb ...\n",
            "Unpacking libpciaccess0:amd64 (0.14-1) ...\n",
            "Selecting previously unselected package libdrm-intel1:amd64.\n",
            "Preparing to unpack .../088-libdrm-intel1_2.4.91-2_amd64.deb ...\n",
            "Unpacking libdrm-intel1:amd64 (2.4.91-2) ...\n",
            "Selecting previously unselected package libdrm-nouveau2:amd64.\n",
            "Preparing to unpack .../089-libdrm-nouveau2_2.4.91-2_amd64.deb ...\n",
            "Unpacking libdrm-nouveau2:amd64 (2.4.91-2) ...\n",
            "Selecting previously unselected package libdrm-radeon1:amd64.\n",
            "Preparing to unpack .../090-libdrm-radeon1_2.4.91-2_amd64.deb ...\n",
            "Unpacking libdrm-radeon1:amd64 (2.4.91-2) ...\n",
            "Selecting previously unselected package libllvm6.0:amd64.\n",
            "Preparing to unpack .../091-libllvm6.0_1%3a6.0-1ubuntu2_amd64.deb ...\n",
            "Unpacking libllvm6.0:amd64 (1:6.0-1ubuntu2) ...\n",
            "Selecting previously unselected package libsensors4:amd64.\n",
            "Preparing to unpack .../092-libsensors4_1%3a3.4.0-4_amd64.deb ...\n",
            "Unpacking libsensors4:amd64 (1:3.4.0-4) ...\n",
            "Selecting previously unselected package libgl1-mesa-dri:amd64.\n",
            "Preparing to unpack .../093-libgl1-mesa-dri_18.0.5-0ubuntu0~18.04.1_amd64.deb ...\n",
            "Unpacking libgl1-mesa-dri:amd64 (18.0.5-0ubuntu0~18.04.1) ...\n",
            "Selecting previously unselected package libglx-mesa0:amd64.\n",
            "Preparing to unpack .../094-libglx-mesa0_18.0.5-0ubuntu0~18.04.1_amd64.deb ...\n",
            "Unpacking libglx-mesa0:amd64 (18.0.5-0ubuntu0~18.04.1) ...\n",
            "Selecting previously unselected package libglx0:amd64.\n",
            "Preparing to unpack .../095-libglx0_1.0.0-2ubuntu2.2_amd64.deb ...\n",
            "Unpacking libglx0:amd64 (1.0.0-2ubuntu2.2) ...\n",
            "Selecting previously unselected package libgl1:amd64.\n",
            "Preparing to unpack .../096-libgl1_1.0.0-2ubuntu2.2_amd64.deb ...\n",
            "Unpacking libgl1:amd64 (1.0.0-2ubuntu2.2) ...\n",
            "Selecting previously unselected package libiec61883-0:amd64.\n",
            "Preparing to unpack .../097-libiec61883-0_1.2.0-2_amd64.deb ...\n",
            "Unpacking libiec61883-0:amd64 (1.2.0-2) ...\n",
            "Selecting previously unselected package libjack-jackd2-0:amd64.\n",
            "Preparing to unpack .../098-libjack-jackd2-0_1.9.12~dfsg-2_amd64.deb ...\n",
            "Unpacking libjack-jackd2-0:amd64 (1.9.12~dfsg-2) ...\n",
            "Selecting previously unselected package libopenal-data.\n",
            "Preparing to unpack .../099-libopenal-data_1%3a1.18.2-2_all.deb ...\n",
            "Unpacking libopenal-data (1:1.18.2-2) ...\n",
            "Selecting previously unselected package libsndio6.1:amd64.\n",
            "Preparing to unpack .../100-libsndio6.1_1.1.0-3_amd64.deb ...\n",
            "Unpacking libsndio6.1:amd64 (1.1.0-3) ...\n",
            "Selecting previously unselected package libopenal1:amd64.\n",
            "Preparing to unpack .../101-libopenal1_1%3a1.18.2-2_amd64.deb ...\n",
            "Unpacking libopenal1:amd64 (1:1.18.2-2) ...\n",
            "Selecting previously unselected package libasyncns0:amd64.\n",
            "Preparing to unpack .../102-libasyncns0_0.8-6_amd64.deb ...\n",
            "Unpacking libasyncns0:amd64 (0.8-6) ...\n",
            "Selecting previously unselected package libflac8:amd64.\n",
            "Preparing to unpack .../103-libflac8_1.3.2-1_amd64.deb ...\n",
            "Unpacking libflac8:amd64 (1.3.2-1) ...\n",
            "Selecting previously unselected package libsndfile1:amd64.\n",
            "Preparing to unpack .../104-libsndfile1_1.0.28-4_amd64.deb ...\n",
            "Unpacking libsndfile1:amd64 (1.0.28-4) ...\n",
            "Selecting previously unselected package libwrap0:amd64.\n",
            "Preparing to unpack .../105-libwrap0_7.6.q-27_amd64.deb ...\n",
            "Unpacking libwrap0:amd64 (7.6.q-27) ...\n",
            "Selecting previously unselected package libpulse0:amd64.\n",
            "Preparing to unpack .../106-libpulse0_1%3a11.1-1ubuntu7.1_amd64.deb ...\n",
            "Unpacking libpulse0:amd64 (1:11.1-1ubuntu7.1) ...\n",
            "Selecting previously unselected package libwayland-cursor0:amd64.\n",
            "Preparing to unpack .../107-libwayland-cursor0_1.14.0-2_amd64.deb ...\n",
            "Unpacking libwayland-cursor0:amd64 (1.14.0-2) ...\n",
            "Selecting previously unselected package libwayland-egl1-mesa:amd64.\n",
            "Preparing to unpack .../108-libwayland-egl1-mesa_18.0.5-0ubuntu0~18.04.1_amd64.deb ...\n",
            "Unpacking libwayland-egl1-mesa:amd64 (18.0.5-0ubuntu0~18.04.1) ...\n",
            "Selecting previously unselected package libxcursor1:amd64.\n",
            "Preparing to unpack .../109-libxcursor1_1%3a1.1.15-1_amd64.deb ...\n",
            "Unpacking libxcursor1:amd64 (1:1.1.15-1) ...\n",
            "Selecting previously unselected package libxi6:amd64.\n",
            "Preparing to unpack .../110-libxi6_2%3a1.7.9-1_amd64.deb ...\n",
            "Unpacking libxi6:amd64 (2:1.7.9-1) ...\n",
            "Selecting previously unselected package libxkbcommon0:amd64.\n",
            "Preparing to unpack .../111-libxkbcommon0_0.8.0-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libxkbcommon0:amd64 (0.8.0-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libxrandr2:amd64.\n",
            "Preparing to unpack .../112-libxrandr2_2%3a1.5.1-1_amd64.deb ...\n",
            "Unpacking libxrandr2:amd64 (2:1.5.1-1) ...\n",
            "Selecting previously unselected package libsdl2-2.0-0:amd64.\n",
            "Preparing to unpack .../113-libsdl2-2.0-0_2.0.8+dfsg1-1ubuntu1.18.04.1_amd64.deb ...\n",
            "Unpacking libsdl2-2.0-0:amd64 (2.0.8+dfsg1-1ubuntu1.18.04.1) ...\n",
            "Selecting previously unselected package libxcb-shape0:amd64.\n",
            "Preparing to unpack .../114-libxcb-shape0_1.13-1_amd64.deb ...\n",
            "Unpacking libxcb-shape0:amd64 (1.13-1) ...\n",
            "Selecting previously unselected package libxv1:amd64.\n",
            "Preparing to unpack .../115-libxv1_2%3a1.0.11-1_amd64.deb ...\n",
            "Unpacking libxv1:amd64 (2:1.0.11-1) ...\n",
            "Selecting previously unselected package libavdevice57:amd64.\n",
            "Preparing to unpack .../116-libavdevice57_7%3a3.4.4-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libavdevice57:amd64 (7:3.4.4-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package ffmpeg.\n",
            "Preparing to unpack .../117-ffmpeg_7%3a3.4.4-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking ffmpeg (7:3.4.4-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libaacs0:amd64.\n",
            "Preparing to unpack .../118-libaacs0_0.9.0-1_amd64.deb ...\n",
            "Unpacking libaacs0:amd64 (0.9.0-1) ...\n",
            "Selecting previously unselected package libbdplus0:amd64.\n",
            "Preparing to unpack .../119-libbdplus0_0.1.2-2_amd64.deb ...\n",
            "Unpacking libbdplus0:amd64 (0.1.2-2) ...\n",
            "Selecting previously unselected package libgdk-pixbuf2.0-bin.\n",
            "Preparing to unpack .../120-libgdk-pixbuf2.0-bin_2.36.11-2_amd64.deb ...\n",
            "Unpacking libgdk-pixbuf2.0-bin (2.36.11-2) ...\n",
            "Selecting previously unselected package librsvg2-common:amd64.\n",
            "Preparing to unpack .../121-librsvg2-common_2.40.20-2_amd64.deb ...\n",
            "Unpacking librsvg2-common:amd64 (2.40.20-2) ...\n",
            "Selecting previously unselected package mesa-va-drivers:amd64.\n",
            "Preparing to unpack .../122-mesa-va-drivers_18.0.5-0ubuntu0~18.04.1_amd64.deb ...\n",
            "Unpacking mesa-va-drivers:amd64 (18.0.5-0ubuntu0~18.04.1) ...\n",
            "Selecting previously unselected package mesa-vdpau-drivers:amd64.\n",
            "Preparing to unpack .../123-mesa-vdpau-drivers_18.0.5-0ubuntu0~18.04.1_amd64.deb ...\n",
            "Unpacking mesa-vdpau-drivers:amd64 (18.0.5-0ubuntu0~18.04.1) ...\n",
            "Selecting previously unselected package i965-va-driver:amd64.\n",
            "Preparing to unpack .../124-i965-va-driver_2.1.0-0ubuntu1_amd64.deb ...\n",
            "Unpacking i965-va-driver:amd64 (2.1.0-0ubuntu1) ...\n",
            "Selecting previously unselected package va-driver-all:amd64.\n",
            "Preparing to unpack .../125-va-driver-all_2.1.0-3_amd64.deb ...\n",
            "Unpacking va-driver-all:amd64 (2.1.0-3) ...\n",
            "Selecting previously unselected package vdpau-driver-all:amd64.\n",
            "Preparing to unpack .../126-vdpau-driver-all_1.1.1-3ubuntu1_amd64.deb ...\n",
            "Unpacking vdpau-driver-all:amd64 (1.1.1-3ubuntu1) ...\n",
            "Setting up libxi6:amd64 (2:1.7.9-1) ...\n",
            "Setting up libxinerama1:amd64 (2:1.1.3-1) ...\n",
            "Setting up libxcb-glx0:amd64 (1.13-1) ...\n",
            "Setting up libtwolame0:amd64 (0.3.13-3) ...\n",
            "Setting up libraw1394-11:amd64 (2.1.2-1) ...\n",
            "Setting up libx264-152:amd64 (2:0.152.2854+gite9a5903-2) ...\n",
            "Setting up libxcb-render0:amd64 (1.13-1) ...\n",
            "Setting up libopenjp2-7:amd64 (2.3.0-1) ...\n",
            "Setting up libasyncns0:amd64 (0.8-6) ...\n",
            "Setting up libxdamage1:amd64 (1:1.1.4-3) ...\n",
            "Setting up libxfixes3:amd64 (1:5.0.3-1) ...\n",
            "Setting up libdrm-amdgpu1:amd64 (2.4.91-2) ...\n",
            "Setting up libllvm6.0:amd64 (1:6.0-1ubuntu2) ...\n",
            "Setting up libwavpack1:amd64 (5.1.0-2ubuntu1.1) ...\n",
            "Setting up libjbig0:amd64 (2.1-3.1build1) ...\n",
            "Setting up libaacs0:amd64 (0.9.0-1) ...\n",
            "Setting up libnuma1:amd64 (2.0.11-2.1) ...\n",
            "Setting up libsoxr0:amd64 (0.1.2-3) ...\n",
            "Setting up libssh-gcrypt-4:amd64 (0.8.0~20170825.94fa1e38-1ubuntu0.1) ...\n",
            "Setting up libasound2-data (1.1.3-5ubuntu0.1) ...\n",
            "Setting up xkb-data (2.23.1-1ubuntu1) ...\n",
            "Setting up libbluray2:amd64 (1:1.0.2-3) ...\n",
            "Setting up libvdpau1:amd64 (1.1.1-3ubuntu1) ...\n",
            "Setting up libgdk-pixbuf2.0-common (2.36.11-2) ...\n",
            "Setting up libdatrie1:amd64 (0.2.10-7) ...\n",
            "Setting up libtiff5:amd64 (4.0.9-5) ...\n",
            "Setting up libshine3:amd64 (3.1.1-1) ...\n",
            "Setting up libva2:amd64 (2.1.0-3) ...\n",
            "Setting up libiec61883-0:amd64 (1.2.0-2) ...\n",
            "Setting up libspeex1:amd64 (1.2~rc1.2-1ubuntu2) ...\n",
            "Setting up libfftw3-double3:amd64 (3.3.7-1) ...\n",
            "Setting up libxvidcore4:amd64 (2:1.3.5-1) ...\n",
            "Setting up libopus0:amd64 (1.1.2-1ubuntu1) ...\n",
            "Setting up libx265-146:amd64 (2.6-3) ...\n",
            "Setting up libasound2:amd64 (1.1.3-5ubuntu0.1) ...\n",
            "Setting up libopenal-data (1:1.18.2-2) ...\n",
            "Setting up libbs2b0:amd64 (3.1.0+dfsg-2.2) ...\n",
            "Setting up libcroco3:amd64 (0.6.12-2) ...\n",
            "Setting up libogg0:amd64 (1.3.2-1) ...\n",
            "Setting up libpixman-1-0:amd64 (0.34.0-2) ...\n",
            "Setting up libmp3lame0:amd64 (3.100-2) ...\n",
            "Setting up libxcursor1:amd64 (1:1.1.15-1) ...\n",
            "Setting up libusb-1.0-0:amd64 (2:1.0.21-2) ...\n",
            "Setting up libcrystalhd3:amd64 (1:0.0~git20110715.fdd2f19-12) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Setting up libsnappy1v5:amd64 (1.1.7-1) ...\n",
            "Setting up libwayland-egl1-mesa:amd64 (18.0.5-0ubuntu0~18.04.1) ...\n",
            "Setting up libva-drm2:amd64 (2.1.0-3) ...\n",
            "Setting up libavc1394-0:amd64 (0.5.4-4build1) ...\n",
            "Setting up libzvbi-common (0.2.35-13) ...\n",
            "Setting up libfribidi0:amd64 (0.19.7-2) ...\n",
            "Setting up libxcb-shm0:amd64 (1.13-1) ...\n",
            "Setting up libxcb-shape0:amd64 (1.13-1) ...\n",
            "Setting up libpciaccess0:amd64 (0.14-1) ...\n",
            "Setting up libxv1:amd64 (2:1.0.11-1) ...\n",
            "Setting up libsensors4:amd64 (1:3.4.0-4) ...\n",
            "Setting up shared-mime-info (1.9-2) ...\n",
            "Setting up libxkbcommon0:amd64 (0.8.0-1ubuntu0.1) ...\n",
            "Setting up libvpx5:amd64 (1.7.0-3) ...\n",
            "Setting up libdrm-radeon1:amd64 (2.4.91-2) ...\n",
            "Setting up libgme0:amd64 (0.6.2-1) ...\n",
            "Setting up libthai-data (0.1.27-2) ...\n",
            "Setting up libbdplus0:amd64 (0.1.2-2) ...\n",
            "Setting up libxxf86vm1:amd64 (1:1.1.4-1) ...\n",
            "Setting up libzvbi0:amd64 (0.2.35-13) ...\n",
            "Setting up libva-x11-2:amd64 (2.1.0-3) ...\n",
            "Setting up libdrm-nouveau2:amd64 (2.4.91-2) ...\n",
            "Setting up libsamplerate0:amd64 (0.1.9-1) ...\n",
            "Setting up libsndio6.1:amd64 (1.1.0-3) ...\n",
            "Setting up libvorbis0a:amd64 (1.3.5-4.2) ...\n",
            "Setting up libmpg123-0:amd64 (1.25.10-1) ...\n",
            "Setting up libslang2:amd64 (2.3.1a-3ubuntu1) ...\n",
            "Setting up libwayland-cursor0:amd64 (1.14.0-2) ...\n",
            "Setting up libgsm1:amd64 (1.0.13-4build1) ...\n",
            "Setting up libmysofa0:amd64 (0.6~dfsg0-2) ...\n",
            "Setting up libcdio17:amd64 (1.0.0-2ubuntu2) ...\n",
            "Setting up libxrandr2:amd64 (2:1.5.1-1) ...\n",
            "Setting up fontconfig (2.12.6-0ubuntu2) ...\n",
            "Regenerating fonts cache... done.\n",
            "Setting up libwrap0:amd64 (7.6.q-27) ...\n",
            "Setting up libwebp6:amd64 (0.6.1-2) ...\n",
            "Setting up libvorbisfile3:amd64 (1.3.5-4.2) ...\n",
            "Setting up libcairo2:amd64 (1.15.10-2) ...\n",
            "Setting up libavutil55:amd64 (7:3.4.4-0ubuntu0.18.04.1) ...\n",
            "Setting up libopenmpt0:amd64 (0.3.6-1) ...\n",
            "Setting up libflite1:amd64 (2.1-release-1) ...\n",
            "Setting up mesa-vdpau-drivers:amd64 (18.0.5-0ubuntu0~18.04.1) ...\n",
            "Setting up libgdk-pixbuf2.0-0:amd64 (2.36.11-2) ...\n",
            "Setting up libass9:amd64 (1:0.14.0-1) ...\n",
            "Setting up libflac8:amd64 (1.3.2-1) ...\n",
            "Setting up libgdk-pixbuf2.0-bin (2.36.11-2) ...\n",
            "Setting up libdc1394-22:amd64 (2.2.5-1) ...\n",
            "Setting up libcdio-cdda2:amd64 (10.2+0.94+2-2build1) ...\n",
            "Setting up libthai0:amd64 (0.1.27-2) ...\n",
            "Setting up libswresample2:amd64 (7:3.4.4-0ubuntu0.18.04.1) ...\n",
            "Setting up libdrm-intel1:amd64 (2.4.91-2) ...\n",
            "Setting up librubberband2:amd64 (1.8.1-7ubuntu2) ...\n",
            "Setting up libswscale4:amd64 (7:3.4.4-0ubuntu0.18.04.1) ...\n",
            "Setting up libwebpmux3:amd64 (0.6.1-2) ...\n",
            "Setting up mesa-va-drivers:amd64 (18.0.5-0ubuntu0~18.04.1) ...\n",
            "Setting up libpango-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Setting up libcdio-paranoia2:amd64 (10.2+0.94+2-2build1) ...\n",
            "Setting up libpostproc54:amd64 (7:3.4.4-0ubuntu0.18.04.1) ...\n",
            "Setting up libjack-jackd2-0:amd64 (1.9.12~dfsg-2) ...\n",
            "Setting up libopenal1:amd64 (1:1.18.2-2) ...\n",
            "Setting up libvorbisenc2:amd64 (1.3.5-4.2) ...\n",
            "Setting up libcaca0:amd64 (0.99.beta19-2build2~gcc5.3) ...\n",
            "Setting up libtheora0:amd64 (1.1.1+dfsg.1-14) ...\n",
            "Setting up vdpau-driver-all:amd64 (1.1.1-3ubuntu1) ...\n",
            "Setting up libavresample3:amd64 (7:3.4.4-0ubuntu0.18.04.1) ...\n",
            "Setting up libgl1-mesa-dri:amd64 (18.0.5-0ubuntu0~18.04.1) ...\n",
            "Setting up libpangoft2-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Setting up libsndfile1:amd64 (1.0.28-4) ...\n",
            "Setting up i965-va-driver:amd64 (2.1.0-0ubuntu1) ...\n",
            "Setting up va-driver-all:amd64 (2.1.0-3) ...\n",
            "Setting up libglx-mesa0:amd64 (18.0.5-0ubuntu0~18.04.1) ...\n",
            "Setting up libpangocairo-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Setting up libpulse0:amd64 (1:11.1-1ubuntu7.1) ...\n",
            "Setting up libsdl2-2.0-0:amd64 (2.0.8+dfsg1-1ubuntu1.18.04.1) ...\n",
            "Setting up libglx0:amd64 (1.0.0-2ubuntu2.2) ...\n",
            "Setting up librsvg2-2:amd64 (2.40.20-2) ...\n",
            "Setting up libavcodec57:amd64 (7:3.4.4-0ubuntu0.18.04.1) ...\n",
            "Setting up librsvg2-common:amd64 (2.40.20-2) ...\n",
            "Setting up libgl1:amd64 (1.0.0-2ubuntu2.2) ...\n",
            "Setting up libchromaprint1:amd64 (1.4.3-1) ...\n",
            "Setting up libavformat57:amd64 (7:3.4.4-0ubuntu0.18.04.1) ...\n",
            "Setting up libavfilter6:amd64 (7:3.4.4-0ubuntu0.18.04.1) ...\n",
            "Setting up libavdevice57:amd64 (7:3.4.4-0ubuntu0.18.04.1) ...\n",
            "Setting up ffmpeg (7:3.4.4-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Processing triggers for libgdk-pixbuf2.0-0:amd64 (2.36.11-2) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libfontenc1 libxaw7 libxfont2 libxkbfile1 libxmu6 libxmuu1 libxpm4 libxt6\n",
            "  x11-xkb-utils xauth xfonts-base xfonts-encodings xfonts-utils xserver-common\n",
            "The following NEW packages will be installed:\n",
            "  libfontenc1 libxaw7 libxfont2 libxkbfile1 libxmu6 libxmuu1 libxpm4 libxt6\n",
            "  x11-xkb-utils xauth xfonts-base xfonts-encodings xfonts-utils xserver-common\n",
            "  xvfb\n",
            "0 upgraded, 15 newly installed, 0 to remove and 5 not upgraded.\n",
            "Need to get 8,167 kB of archives.\n",
            "After this operation, 13.0 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxmuu1 amd64 2:1.1.2-2 [9,674 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 xauth amd64 1:1.0.10-1 [24.6 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfontenc1 amd64 1:1.1.3-1 [13.9 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxt6 amd64 1:1.1.5-1 [160 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxmu6 amd64 2:1.1.2-2 [46.0 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxpm4 amd64 1:3.5.12-1 [34.0 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxaw7 amd64 2:1.0.13-1 [173 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxfont2 amd64 1:2.0.3-1 [91.7 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxkbfile1 amd64 1:1.0.9-2 [64.6 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 x11-xkb-utils amd64 7.7+3ubuntu0.18.04.1 [160 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 xfonts-encodings all 1:1.0.4-2 [573 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 xfonts-utils amd64 1:7.7+6 [91.5 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 xfonts-base all 1:1.0.4+nmu1 [5,914 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 xserver-common all 2:1.19.6-1ubuntu4.2 [27.3 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.2 [783 kB]\n",
            "Fetched 8,167 kB in 0s (37.2 MB/s)\n",
            "Selecting previously unselected package libxmuu1:amd64.\n",
            "(Reading database ... 26144 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libxmuu1_2%3a1.1.2-2_amd64.deb ...\n",
            "Unpacking libxmuu1:amd64 (2:1.1.2-2) ...\n",
            "Selecting previously unselected package xauth.\n",
            "Preparing to unpack .../01-xauth_1%3a1.0.10-1_amd64.deb ...\n",
            "Unpacking xauth (1:1.0.10-1) ...\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "Preparing to unpack .../02-libfontenc1_1%3a1.1.3-1_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.3-1) ...\n",
            "Selecting previously unselected package libxt6:amd64.\n",
            "Preparing to unpack .../03-libxt6_1%3a1.1.5-1_amd64.deb ...\n",
            "Unpacking libxt6:amd64 (1:1.1.5-1) ...\n",
            "Selecting previously unselected package libxmu6:amd64.\n",
            "Preparing to unpack .../04-libxmu6_2%3a1.1.2-2_amd64.deb ...\n",
            "Unpacking libxmu6:amd64 (2:1.1.2-2) ...\n",
            "Selecting previously unselected package libxpm4:amd64.\n",
            "Preparing to unpack .../05-libxpm4_1%3a3.5.12-1_amd64.deb ...\n",
            "Unpacking libxpm4:amd64 (1:3.5.12-1) ...\n",
            "Selecting previously unselected package libxaw7:amd64.\n",
            "Preparing to unpack .../06-libxaw7_2%3a1.0.13-1_amd64.deb ...\n",
            "Unpacking libxaw7:amd64 (2:1.0.13-1) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../07-libxfont2_1%3a2.0.3-1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.3-1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../08-libxkbfile1_1%3a1.0.9-2_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.0.9-2) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../09-x11-xkb-utils_7.7+3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../10-xfonts-encodings_1%3a1.0.4-2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.4-2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../11-xfonts-utils_1%3a7.7+6_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../12-xfonts-base_1%3a1.0.4+nmu1_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.4+nmu1) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../13-xserver-common_2%3a1.19.6-1ubuntu4.2_all.deb ...\n",
            "Unpacking xserver-common (2:1.19.6-1ubuntu4.2) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../14-xvfb_2%3a1.19.6-1ubuntu4.2_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.2) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.0.9-2) ...\n",
            "Setting up xfonts-encodings (1:1.0.4-2) ...\n",
            "Setting up libxmuu1:amd64 (2:1.1.2-2) ...\n",
            "Setting up xauth (1:1.0.10-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.3-1) ...\n",
            "Setting up libxpm4:amd64 (1:3.5.12-1) ...\n",
            "Setting up libxt6:amd64 (1:1.1.5-1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.3-1) ...\n",
            "Setting up xfonts-utils (1:7.7+6) ...\n",
            "Setting up libxmu6:amd64 (2:1.1.2-2) ...\n",
            "Setting up xfonts-base (1:1.0.4+nmu1) ...\n",
            "Setting up libxaw7:amd64 (2:1.0.13-1) ...\n",
            "Setting up x11-xkb-utils (7.7+3ubuntu0.18.04.1) ...\n",
            "Setting up xserver-common (2:1.19.6-1ubuntu4.2) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.2) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  freeglut3 libglu1-mesa\n",
            "Suggested packages:\n",
            "  python-numpy libgle3\n",
            "The following NEW packages will be installed:\n",
            "  freeglut3 libglu1-mesa python-opengl\n",
            "0 upgraded, 3 newly installed, 0 to remove and 5 not upgraded.\n",
            "Need to get 738 kB of archives.\n",
            "After this operation, 6,207 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 freeglut3 amd64 2.8.1-3 [73.6 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libglu1-mesa amd64 9.0.0-2.1build1 [168 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-opengl all 3.1.0+dfsg-1 [496 kB]\n",
            "Fetched 738 kB in 0s (6,644 kB/s)\n",
            "Selecting previously unselected package freeglut3:amd64.\n",
            "(Reading database ... 26738 files and directories currently installed.)\n",
            "Preparing to unpack .../freeglut3_2.8.1-3_amd64.deb ...\n",
            "Unpacking freeglut3:amd64 (2.8.1-3) ...\n",
            "Selecting previously unselected package libglu1-mesa:amd64.\n",
            "Preparing to unpack .../libglu1-mesa_9.0.0-2.1build1_amd64.deb ...\n",
            "Unpacking libglu1-mesa:amd64 (9.0.0-2.1build1) ...\n",
            "Selecting previously unselected package python-opengl.\n",
            "Preparing to unpack .../python-opengl_3.1.0+dfsg-1_all.deb ...\n",
            "Unpacking python-opengl (3.1.0+dfsg-1) ...\n",
            "Setting up freeglut3:amd64 (2.8.1-3) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Setting up libglu1-mesa:amd64 (9.0.0-2.1build1) ...\n",
            "Setting up python-opengl (3.1.0+dfsg-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading https://files.pythonhosted.org/packages/39/37/f285403a09cc261c56b6574baace1bdcf4b8c7428c8a7239cbba137bc0eb/PyVirtualDisplay-0.2.1.tar.gz\n",
            "Collecting EasyProcess (from pyvirtualdisplay)\n",
            "  Downloading https://files.pythonhosted.org/packages/0d/f1/d2de7591e7dfc164d286fa16f051e6c0cf3141825586c3b04ae7cda7ac0f/EasyProcess-0.2.3.tar.gz\n",
            "Building wheels for collected packages: pyvirtualdisplay, EasyProcess\n",
            "  Running setup.py bdist_wheel for pyvirtualdisplay ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/d1/8c/16/1c64227974ae29c687e4cc30fd691d5c0fd40f54446dde99da\n",
            "  Running setup.py bdist_wheel for EasyProcess ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/b4/c6/e3/c163b04029d8fccfd54b809802640c1af587a01be8d7a04e1a\n",
            "Successfully built pyvirtualdisplay EasyProcess\n",
            "Installing collected packages: EasyProcess, pyvirtualdisplay\n",
            "Successfully installed EasyProcess-0.2.3 pyvirtualdisplay-0.2.1\n",
            "Collecting piglet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/f6/ef278239ebe525466ea51a7dd9d6d3211d197ac4b4abc76e17cdd419f69c/piglet-0.4.4.tar.gz (52kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 5.4MB/s \n",
            "\u001b[?25hCollecting Parsley (from piglet)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/d6/4fed8d65e28a970e1c5cb33ce9c7e22e3de745e1b2ae37af051ef16aea3b/Parsley-1.3-py2.py3-none-any.whl (88kB)\n",
            "\u001b[K    100% |████████████████████████████████| 92kB 13.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from piglet) (18.2.0)\n",
            "Collecting astunparse (from piglet)\n",
            "  Downloading https://files.pythonhosted.org/packages/0d/9d/1576217f67e7420f5945c15c6afd7045178c4850b148741bdbdbdabbf40e/astunparse-1.6.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.6/dist-packages (from piglet) (1.1.0)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from astunparse->piglet) (1.11.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from astunparse->piglet) (0.32.3)\n",
            "Building wheels for collected packages: piglet\n",
            "  Running setup.py bdist_wheel for piglet ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/c7/59/a5/5bd1a35a4a4596714c4c7925a1751e7b1580b6ced363fd7969\n",
            "Successfully built piglet\n",
            "Installing collected packages: Parsley, astunparse, piglet\n",
            "Successfully installed Parsley-1.3 astunparse-1.6.1 piglet-0.4.4\n",
            "Collecting gym\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/22/4ff09745ade385ffe707fb5f053548f0f6a6e7d5e98a2b9d6c07f5b931a7/gym-0.10.9.tar.gz (1.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.5MB 17.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.14.6)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (2.18.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym) (1.11.0)\n",
            "Collecting pyglet>=1.2.0 (from gym)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/fc/dad5eaaab68f0c21e2f906a94ddb98175662cc5a654eee404d59554ce0fa/pyglet-1.3.2-py2.py3-none-any.whl (1.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.0MB 19.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2018.10.15)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym) (0.16.0)\n",
            "Building wheels for collected packages: gym\n",
            "  Running setup.py bdist_wheel for gym ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/6c/3a/0e/b86dee98876bb56cdb482cc1f72201035e46d1baf69d10d028\n",
            "Successfully built gym\n",
            "Installing collected packages: pyglet, gym\n",
            "Successfully installed gym-0.10.9 pyglet-1.3.2\n",
            "Collecting pyopengl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/1d/4544708aaa89f26c97cc09450bb333a23724a320923e74d73e028b3560f9/PyOpenGL-3.1.0.tar.gz (1.2MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.2MB 16.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyopengl\n",
            "  Running setup.py bdist_wheel for pyopengl ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/6c/00/7f/1dd736f380848720ad79a1a1de5272e0d3f79c15a42968fb58\n",
            "Successfully built pyopengl\n",
            "Installing collected packages: pyopengl\n",
            "Successfully installed pyopengl-3.1.0\n",
            "tcmalloc: large alloc 1073750016 bytes == 0x58946000 @  0x7f770424d2a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "931b3dfcc3a02b92b499929fb27299cb",
          "grade": false,
          "grade_id": "cell-fc69f22067705372",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "0NkUrphDBhpb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from tqdm import tqdm as _tqdm\n",
        "\n",
        "def tqdm(*args, **kwargs):\n",
        "    return _tqdm(*args, **kwargs, mininterval=1)  # Safety, do not overflow buffer\n",
        "\n",
        "EPS = float(np.finfo(np.float32).eps)\n",
        "\n",
        "assert sys.version_info[:3] >= (3, 6, 0), \"Make sure you have Python 3.6 installed!\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "e27fe8f72a248bbcf1f7a21e5550e657",
          "grade": true,
          "grade_id": "cell-39519f4ab05eb2a1",
          "locked": true,
          "points": 0,
          "schema_version": 1,
          "solution": false
        },
        "id": "Hk5P8dwLBhpi",
        "colab_type": "code",
        "outputId": "a1a88bf9-7f97-4803-9d35-9c661fa580a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "import gym\n",
        "env = gym.envs.make(\"CartPole-v0\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
            "  result = entry_point.load(False)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "e83ecfc2751cf2e6ff05d0c01d311673",
          "grade": false,
          "grade_id": "cell-fef7e20e54e6243b",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "jZNfjntlBhpg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 1. Deep Q-Network (DQN) (10 (+ 2 bonus) points)"
      ]
    },
    {
      "metadata": {
        "id": "MHweK4dnBhpn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# env is a TimeLimit wrapper around an env, so use env.env to look into the env (but otherwise you can forget about this)\n",
        "??env.env"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lDRpECt7Bhpr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "# The nice thing about the CARTPOLE is that it has very nice rendering functionality (if you are on a local environment). Let's have a look at an episode\n",
        "\n",
        "obs = env.reset()\n",
        "\n",
        "# env.render()\n",
        "\n",
        "done = False\n",
        "while not done:\n",
        "    obs, reward, done, _ = env.step(env.action_space.sample())\n",
        "#     env.render()\n",
        "    \n",
        "    time.sleep(0.05)\n",
        "env.close()  # Close the environment or you will have a lot of render screens soon"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "11a9c014ee5fbe790ce999428cc22658",
          "grade": false,
          "grade_id": "cell-2d83f70e62b99520",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "JhV_Cw42Bhpv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Remember from the previous lab, that in order to optimize a policy we need to estimate the Q-values (e.g. estimate the *action* values). In the CartPole problem, our state is current position of the cart, the current velocity of the cart, the current (angular) position of the pole and the (angular) speed of the pole. As these are continuous variables, we have an infinite number of states (ignoring the fact that a digital computer can only represent finitely many states in finite memory)."
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "9692b7acb09d018d9f80ce95685b81d5",
          "grade": false,
          "grade_id": "cell-bf2ac21267daffbb",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "QYLRY8s_Bhpw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Can you think of a way in which we can still use a tabular approach? Why would this work and can you think of an example problem where this would not work?"
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "3ffce6fca4071a1b543186db1b74cc98",
          "grade": true,
          "grade_id": "cell-b0fa2cb0c2cd2a63",
          "locked": false,
          "points": 1,
          "schema_version": 1,
          "solution": true
        },
        "id": "bdkGJ-wHBhpy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can quantize the continuous variables into bins thus allowing us to use tabular approach. This is due to the fact that each continuous state will now be able to be associated with a specific bin thus making states discrete.\n",
        "Also, using large discretization step, we can reduce number of states from infinitely many to some finite number, which can fit into the memory. \n",
        "\n",
        "As we have seen in the previous lab, tabular learning methods such as Q-learning and SARSA actually learn pretty well so if the discretization step is large enough to make it possible for those algorithms to explore state space, we are guaranteed that they will perform somewhat good.\n",
        "\n",
        "However, if we need to be able to approximate continuous state space with enough precision (i.e. balancing pole cart with high precision where if angular position of the pole changes by infinitesimal degree, we need to change the action), tabular approach won't work anymore as it would have to store an infinite amount of states, which is not feasible."
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "cd66b44d93f348df1e0ef8353377c879",
          "grade": false,
          "grade_id": "cell-0b3162496f5e6cf5",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "UbhnIhGRBhpz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.1 Implement Q-Network"
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "84b9c38718c952ef8e62486fc9bf5e4a",
          "grade": false,
          "grade_id": "cell-96a86bcfa1ebc84a",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "ziDUlKPZBhp1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will not use the tabular approach but approximate the Q-value function by a general approximator function. We will skip the linear case and directly use a two layer Neural Network. We use [PyTorch](https://pytorch.org/) to implement the network, as this will allow us to train it easily later. We can implement a model using `torch.nn.Sequential`, but with PyTorch it is actually very easy to implement the model (e.g. the forward pass) from scratch. Now implement the `QNetwork.forward` function that uses one hidden layer with ReLU activation (no output activation)."
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "4ef7d14363dc2aa4beb638856c57a58c",
          "grade": false,
          "grade_id": "cell-216429a5dccf8a0e",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "VGg-Vn7FBhp2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class QNetwork(nn.Module):\n",
        "    \n",
        "    def __init__(self, num_hidden=128):\n",
        "        nn.Module.__init__(self)\n",
        "        self.l1 = nn.Linear(4, num_hidden)\n",
        "        self.l2 = nn.Linear(num_hidden, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.l1(x)\n",
        "        x = torch.relu(x)\n",
        "        out = self.l2(x)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "2b9a48f9aee9ebc46da01c6f11cd789a",
          "grade": true,
          "grade_id": "cell-00ce108d640a5942",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "id": "IWI0OBriBhp7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Let's instantiate and test if it works\n",
        "num_hidden = 128\n",
        "torch.manual_seed(1234)\n",
        "model = QNetwork(num_hidden)\n",
        "\n",
        "torch.manual_seed(1234)\n",
        "test_model = nn.Sequential(\n",
        "    nn.Linear(4, num_hidden), \n",
        "    nn.ReLU(), \n",
        "    nn.Linear(num_hidden, 2)\n",
        ")\n",
        "\n",
        "x = torch.rand(10, 4)\n",
        "\n",
        "# If you do not need backpropagation, wrap the computation in the torch.no_grad() context\n",
        "# This saves time and memory, and PyTorch complaints when converting to numpy\n",
        "with torch.no_grad():\n",
        "    assert np.allclose(model(x).numpy(), test_model(x).numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "7fc82889691dbd60ff9469b770744fcc",
          "grade": false,
          "grade_id": "cell-ca77eae2e62180cf",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "LCWg5Lw0Bhp_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.2 Experience Replay"
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "5b3265bef151a12fe6969c378af76be2",
          "grade": false,
          "grade_id": "cell-b5b012e42dd2029e",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "EugwDtcrBhqA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "What could be a problem with doing gradient updates on a sequence of state, action pairs $((s_t, a_t), (s_{t+1}, a_{t+1}) ...)$ observed while interacting with the environment? How will using *experience replay* help to overcome this (potential problem)?"
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "75e1a8b00b2bfa9b7dd8805b371c6a4e",
          "grade": true,
          "grade_id": "cell-70a2e59541668a25",
          "locked": false,
          "points": 1,
          "schema_version": 1,
          "solution": true
        },
        "id": "rs7_Hr6IBhqB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "9b3bbd8aaf3aade515736d0d07917a61",
          "grade": false,
          "grade_id": "cell-2c1d117a1a75fd69",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "D_GHjptMBhqD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now implement the `push` function that adds a transition to the replay buffer, and the sample function that returns a batch of samples. It should keep at most the maximum number of transitions. Also implement the `sample` function that samples a (random!) batch of data, for use during training (hint: you can use the function `random.sample`)."
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "93a9f55f3950fe63b44aa84c5fd7f793",
          "grade": false,
          "grade_id": "cell-a3cc876e51eb157f",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "lg-TH5TFBhqE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "class ReplayMemory:\n",
        "    \n",
        "    def __init__(self, capacity):\n",
        "        self.capacity = capacity\n",
        "        self.memory = []\n",
        "\n",
        "    def push(self, transition):\n",
        "        self.memory.append(transition)\n",
        "        if len(self.memory) == self.capacity:\n",
        "            self.memory = self.memory[1:]\n",
        "            \n",
        "    def sample(self, batch_size):\n",
        "        sample = random.sample(self.memory, batch_size)\n",
        "        return sample\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "6865749b3a8810bdaaf1604a9cea42e7",
          "grade": true,
          "grade_id": "cell-3b90135921c4da76",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "id": "8EqgkyWGBhqH",
        "colab_type": "code",
        "outputId": "ee43784d-11ed-4301-f4b0-a0b434c46f8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "capacity = 10\n",
        "memory = ReplayMemory(capacity)\n",
        "\n",
        "# Sample a transition\n",
        "s = env.reset()\n",
        "a = env.action_space.sample()\n",
        "s_next, r, done, _ = env.step(a)\n",
        "\n",
        "# Push a transition\n",
        "memory.push((s, a, r, s_next, done))\n",
        "\n",
        "# Sample a batch size of 1\n",
        "print(memory.sample(1))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(array([-0.03322231, -0.00945505, -0.03911515, -0.0127    ]), 0, 1.0, array([-0.03341141, -0.20399484, -0.03936915,  0.26738956]), False)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "3c742d499c0f9b7f10d1c0c3a085236a",
          "grade": false,
          "grade_id": "cell-88f67e3c051da6a9",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "QR2Bc5z6BhqR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.3 $\\epsilon$psilon greedy policy"
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "61d26d0dec0133f2aa737ed4711d6e08",
          "grade": false,
          "grade_id": "cell-aa3c7d1b3000f697",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "kZchJus-BhqS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In order to learn a good policy, we need to explore quite a bit initially. As we start to learn a good policy, we want to decrease the exploration. As the amount of exploration using an $\\epsilon$-greedy policy is controlled by $\\epsilon$, we can define an 'exploration scheme' by writing $\\epsilon$ as a function of time. There are many possible schemes, but we will use a simple one: we will start with only exploring (so taking random actions) at iteration 0, and then in 1000 iterations linearly anneal $\\epsilon$ such that after 1000 iterations we take random (exploration) actions with 5\\% probability (forever, as you never know if the environment will change)."
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "270ab31d4bb29dc9a05223c16a4967a7",
          "grade": false,
          "grade_id": "cell-5789e7a792108576",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "954Eh0wUBhqT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_epsilon(it):\n",
        "    return 1 if it < 1000 else 0.05"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "b1a81dd07e1b7a98d2cd06ebc171ebdd",
          "grade": true,
          "grade_id": "cell-40e66db45e742b2e",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "id": "wW5ExCX3BhqY",
        "colab_type": "code",
        "outputId": "97854f64-de9a-4baa-c108-81c54105b0c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "cell_type": "code",
      "source": [
        "# So what's an easy way to check?\n",
        "plt.plot([get_epsilon(it) for it in range(5000)])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe6ac4f3d30>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnaNXlgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fe6ac4fe080>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "84685c23e4eb899d7fed3a87b7f8915e",
          "grade": false,
          "grade_id": "cell-a8b604c9998c6c3b",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "aXaunyR7Bhqf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now write a function that takes a state and uses the Q-network to select an ($\\epsilon$-greedy) action. It should return a random action with probability epsilon (which we will pass later). Note, you do not need to backpropagate through the model computations, so use `with torch.no_grad():` (see above for example). Unlike numpy, PyTorch has no argmax function, but Google is your friend... Note that to convert a PyTorch tensor with only 1 element (0 dimensional) to a simple python scalar (int or float), you can use the '.item()' function."
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "882f51819100c850120e73340aec387d",
          "grade": false,
          "grade_id": "cell-878ad3a637cfb51c",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "VHN-vK_fBhqg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def select_action(model, state, epsilon):\n",
        "    with torch.no_grad():\n",
        "        actions = model(torch.FloatTensor(state))\n",
        "#         print(actions)\n",
        "        argmax = torch.max(actions, 0)[1]\n",
        "        action = np.random.choice(2,1, \n",
        "                                  p = [epsilon / 2 + ((1-epsilon) if i == argmax else 0) for i in range(2)])\n",
        "        \n",
        "#         p = [epsilon / 2 + ((1-epsilon) if i == argmax else 0) for i in range(2)]\n",
        "#         print(p)\n",
        "    return action[0]\n",
        "\n",
        "\n",
        "# def select_action(model, state, epsilon):\n",
        "#     with torch.no_grad():\n",
        "#         state = torch.FloatTensor(state).view(-1, 4)\n",
        "#         n = state.s\n",
        "#         actions = model(torch.FloatTensor(state))\n",
        "#         probs = torch.ones(state.shape[0], 2) * epsilon / 2\n",
        "#         argmax = torch.max(actions, 0)\n",
        "# #         action = np.random.choice(2,1, \n",
        "# #                                   p = [epsilon / 2 + ((1-epsilon) if i == argmax else 0) for i in range(2)])\n",
        "#         print(argmax)\n",
        "#         probs += argmax * (1 - epsilon)\n",
        "#         action = torch.multinomial(\n",
        "#             probs, 1\n",
        "#         )\n",
        "# #         p = [epsilon / 2 + ((1-epsilon) if i == argmax else 0) for i in range(2)]\n",
        "#         print(probs)\n",
        "#         print(action)\n",
        "#     return action[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "21f939075cb0c8dde152dabf47568a9d",
          "grade": true,
          "grade_id": "cell-e895338d56bee477",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "id": "HhhLoy5LBhqk",
        "colab_type": "code",
        "outputId": "a6e33b14-7a97-4d78-f6db-10af125c9b2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "s = env.reset()\n",
        "a = select_action(model, s, 0.05)\n",
        "assert not torch.is_tensor(a)\n",
        "print (a)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "5d00ab2e5e0b39257771d0e778fda2d6",
          "grade": false,
          "grade_id": "cell-ec5e94e0b03f8aec",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "OimCXVQ-Bhqw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.4 Training function"
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "4839aac72a80552046ebecc40c1615cf",
          "grade": false,
          "grade_id": "cell-d1a12cc97386fe56",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "jWKRLwvWBhqy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we will implement the function 'train' that samples a batch from the memory and performs a gradient step using some convenient PyTorch functionality. However, you still need to compute the Q-values for the (state, action) pairs in the experience, as well as their target (e.g. the value they should move towards). What is the target for a Q-learning update? What should be the target if `next_state` is terminal (e.g. `done`)?\n",
        "\n",
        "For computing the Q-values for the actions, note that the model returns all action values where you are only interested in a single action value. Because of the batch dimension, you can't use simple indexing, but you may want to have a look at [torch.gather](https://pytorch.org/docs/stable/torch.html?highlight=gather#torch.gather) or use [advanced indexing](https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html) (numpy tutorial but works mostly the same in PyTorch). Note, you should NOT modify the function train. You can view the size of a tensor `x` with `x.size()` (similar to `x.shape` in numpy)."
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "c466ee49add35cb1ec6a3e4a85f733c9",
          "grade": false,
          "grade_id": "cell-6c45485324b40081",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "Dm3vEDA4Bhqz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def compute_q_val(model, state, action):\n",
        "    actions = model(torch.FloatTensor(state))\n",
        "#     print(actions)\n",
        "    return actions[range(len(state)), action]\n",
        "    \n",
        "    \n",
        "def compute_target(model, reward, next_state, done, discount_factor):\n",
        "    # done is a boolean (vector) that indicates if next_state is terminal (episode is done)\n",
        "    # YOUR CODE HERE\n",
        "    # TODO (but not so much): do this ugly sht in batch, but have to change select_aciton to be batches.\n",
        "    #                         see attempt on commented code\n",
        "    best_action = [select_action(model, s, 0) for s in next_state]\n",
        "    # TODO: is it the correct way of handling done?\n",
        "    # i just say 0 if its terminal 1 oth\n",
        "    target = reward + discount_factor * compute_q_val(model, next_state, best_action) * (1- done.float())\n",
        "    return target\n",
        "\n",
        "def train(model, memory, optimizer, batch_size, discount_factor):\n",
        "    # DO NOT MODIFY THIS FUNCTION\n",
        "    \n",
        "    # don't learn without some decent experience\n",
        "    if len(memory) < batch_size:\n",
        "        return None\n",
        "\n",
        "    # random transition batch is taken from experience replay memory\n",
        "    transitions = memory.sample(batch_size)\n",
        "    \n",
        "    # transition is a list of 4-tuples, instead we want 4 vectors (as torch.Tensor's)\n",
        "    state, action, reward, next_state, done = zip(*transitions)\n",
        "    \n",
        "    # convert to PyTorch and define types\n",
        "    state = torch.tensor(state, dtype=torch.float)\n",
        "    action = torch.tensor(action, dtype=torch.int64)  # Need 64 bit to use them as index\n",
        "    next_state = torch.tensor(next_state, dtype=torch.float)\n",
        "    reward = torch.tensor(reward, dtype=torch.float)\n",
        "    done = torch.tensor(done, dtype=torch.uint8)  # Boolean\n",
        "    \n",
        "    # compute the q value\n",
        "    q_val = compute_q_val(model, state, action)\n",
        "    \n",
        "    with torch.no_grad():  # Don't compute gradient info for the target (semi-gradient)\n",
        "        target = compute_target(model, reward, next_state, done, discount_factor)\n",
        "    \n",
        "    # loss is measured from error between current and newly expected Q values\n",
        "    loss = F.smooth_l1_loss(q_val, target)\n",
        "\n",
        "    # backpropagation of loss to Neural Network (PyTorch magic)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    return loss.item()  # Returns a Python scalar, and releases history (similar to .detach())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "877c400001292b619e6871c1366524b9",
          "grade": true,
          "grade_id": "cell-b060b822eec4282f",
          "locked": true,
          "points": 2,
          "schema_version": 1,
          "solution": false
        },
        "id": "4JdUbeMfBhq4",
        "colab_type": "code",
        "outputId": "949e96c3-a668-4723-b956-49876711e026",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# You may want to test your functions individually, but after you do so lets see if the method train works.\n",
        "batch_size = 64\n",
        "discount_factor = 0.8\n",
        "learn_rate = 1e-3\n",
        "# Simple gradient descent may take long, so we will use Adam\n",
        "optimizer = optim.Adam(model.parameters(), learn_rate)\n",
        "\n",
        "# We need a larger memory, fill with dummy data\n",
        "transition = memory.sample(1)[0]\n",
        "memory = ReplayMemory(10 * batch_size)\n",
        "for i in range(batch_size):\n",
        "    memory.push(transition)\n",
        "\n",
        "# Now let's see if it works\n",
        "loss = train(model, memory, optimizer, batch_size, discount_factor)\n",
        "\n",
        "print (loss)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5962719321250916\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "2057dee580a43fb0442fe52557c0ac64",
          "grade": false,
          "grade_id": "cell-3eafd0ab49103f3b",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "Pl5Su__lBhq8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.5 Put it all together"
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "06dd71aae5c3c699f2b707b348a88107",
          "grade": false,
          "grade_id": "cell-36b8a04b393d8104",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "m4I3spTCBhq9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now that you have implemented the training step, you should be able to put everything together. Implement the function `run_episodes` that runs a number of episodes of DQN training. It should return the durations (e.g. number of steps) of each episode. Note: we pass the train function as an argument such that we can swap it for a different training step later."
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "c3f61b2ca270d84ab9b28d989dd65d4c",
          "grade": false,
          "grade_id": "cell-540a7d50ecc1d046",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "xf-BeXFNBhq-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run_episodes(train, model, memory, env, num_episodes, batch_size, discount_factor, learn_rate):\n",
        "    \n",
        "    optimizer = optim.Adam(model.parameters(), learn_rate)\n",
        "    \n",
        "    global_steps = 0  # Count the steps (do not reset at episode start, to compute epsilon)\n",
        "    episode_durations = []  #\n",
        "    for i in range(num_episodes):\n",
        "        duration = 0\n",
        "        s = env.reset()\n",
        "        \n",
        "        while True: \n",
        "            epsilon = get_epsilon(i)\n",
        "            a = select_action(model, s, epsilon)\n",
        "\n",
        "            next_state, r, done, _ = env.step(a)\n",
        "            # TODO: is it correct to compute duration here and not after the break?\n",
        "            duration += 1\n",
        "            \n",
        "            memory.push((s, a, r, next_state, done))\n",
        "            \n",
        "            if done: \n",
        "                break\n",
        "                \n",
        "            s = next_state\n",
        "        \n",
        "        loss = train(model, memory, optimizer, batch_size, discount_factor)\n",
        "        \n",
        "        episode_durations.append(duration)\n",
        "        \n",
        "    return episode_durations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2M1_xGZLBhrD",
        "colab_type": "code",
        "outputId": "cb1e761e-87e6-4f59-dc55-b8e14be07175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        }
      },
      "cell_type": "code",
      "source": [
        "# Let's run it!\n",
        "num_episodes = 2000\n",
        "batch_size = 64\n",
        "discount_factor = 0.8\n",
        "learn_rate = 1e-3\n",
        "memory = ReplayMemory(10000)\n",
        "num_hidden = 128\n",
        "seed = 42  # This is not randomly chosen\n",
        "\n",
        "# We will seed the algorithm (before initializing QNetwork!) for reproducability\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "env.seed(seed)\n",
        "\n",
        "model = QNetwork(num_hidden)\n",
        "\n",
        "episode_durations = run_episodes(train, model, memory, env, num_episodes, batch_size, discount_factor, learn_rate)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-11b5e7db3456>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mepisode_durations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_episodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_episodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscount_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-85177e2410de>\u001b[0m in \u001b[0;36mrun_episodes\u001b[0;34m(train, model, memory, env, num_episodes, batch_size, discount_factor, learn_rate)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mduration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-119d57b294a0>\u001b[0m in \u001b[0;36mpush\u001b[0;34m(self, transition)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapacity\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "iXuRPz1bnOLR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "70d16eb61eae34605e8d7813a70a604a",
          "grade": true,
          "grade_id": "cell-928ecc11ed5c43d8",
          "locked": true,
          "points": 2,
          "schema_version": 1,
          "solution": false
        },
        "id": "U5eA1Ti6BhrH",
        "colab_type": "code",
        "outputId": "a9921a2f-f1f9-44c2-fd96-767540b441fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "cell_type": "code",
      "source": [
        "# And see the results\n",
        "def smooth(x, N):\n",
        "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
        "    return (cumsum[N:] - cumsum[:-N]) / float(N)\n",
        "\n",
        "plt.plot(smooth(episode_durations, 10))\n",
        "plt.title('Episode durations per episode')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-6d9c8b582dc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcumsum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmooth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode_durations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Episode durations per episode'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'episode_durations' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "1e106dba734da10d4d8b3bf90d6bb772",
          "grade": false,
          "grade_id": "cell-49e6bf74834a67ef",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "-vURScBlBhrL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.6 Semi-gradient vs. true gradient (bonus)"
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "acf155c686f3916453a3d11d95994987",
          "grade": false,
          "grade_id": "cell-fc30be2a6983bc77",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "K5YX6qqtBhrM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note that by using automatic differentiation in PyTorch, it is (relatively) easy to implement the true gradient method. Hint: PyTorch may complain about computing gradients for the target in [smooth_l1_loss](https://pytorch.org/docs/stable/nn.html?highlight=smooth_l1_loss#torch.nn.functional.smooth_l1_loss). How can you circumvent this problem? Implement the `train_true_gradient` method below."
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "3d1e72257ed8c59175352e163f1bfdaf",
          "grade": true,
          "grade_id": "cell-71707640573b23d1",
          "locked": false,
          "points": 1,
          "schema_version": 1,
          "solution": true
        },
        "id": "b_7fZisvBhrO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_true_gradient(model, memory, optimizer, batch_size, discount_factor):\n",
        "    \n",
        "    # don't learn without some decent experience\n",
        "    if len(memory) < batch_size:\n",
        "        return None\n",
        "\n",
        "    # random transition batch is taken from experience replay memory\n",
        "    transitions = memory.sample(batch_size)\n",
        "    \n",
        "    # transition is a list of 4-tuples, instead we want 4 vectors (as torch.Tensor's)\n",
        "    state, action, reward, next_state, done = zip(*transitions)\n",
        "    \n",
        "    # convert to PyTorch and define types\n",
        "    state = torch.tensor(state, dtype=torch.float)\n",
        "    action = torch.tensor(action, dtype=torch.int64)  # Need 64 bit to use them as index\n",
        "    next_state = torch.tensor(next_state, dtype=torch.float)\n",
        "    reward = torch.tensor(reward, dtype=torch.float)\n",
        "    done = torch.tensor(done, dtype=torch.uint8)  # Boolean\n",
        "    \n",
        "    # compute the q value\n",
        "    q_val = compute_q_val(model, state, action)\n",
        "    \n",
        "#     with torch.no_grad():  # Don't compute gradient info for the target (semi-gradient)\n",
        "    target = compute_target(model, reward, next_state, done, discount_factor)\n",
        "    \n",
        "    # loss is measured from error between current and newly expected Q values\n",
        "    loss = F.smooth_l1_loss(q_val, target)\n",
        "\n",
        "    # backpropagation of loss to Neural Network (PyTorch magic)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    return loss.item()  # Returns a Python scalar, and releases history (similar to .detach())\n",
        "\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "env.seed(seed)\n",
        "\n",
        "model = QNetwork(num_hidden)\n",
        "\n",
        "episode_durations_true_gradient = run_episodes(\n",
        "    train_true_gradient, model, memory, env, num_episodes, batch_size, discount_factor, learn_rate)\n",
        "\n",
        "plt.plot(smooth(episode_durations, 10))\n",
        "plt.plot(smooth(episode_durations_true_gradient, 10))\n",
        "plt.title('Episode durations per episode')\n",
        "plt.legend(['Semi-gradient', 'True gradient'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "95b462060bc00fccd7e8bc2ccc857215",
          "grade": false,
          "grade_id": "cell-b6fb5a1b0894fb4e",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "I4UPQmtdBhrU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Which algorithm performs better? Is this what you would expect? Can you explain this?\n",
        "\n",
        "Note: you may want to play around with the number of episodes to answer this question, but please reset it to 100 before handing in the notebook."
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "b2e5712195d20cce7d1a6afb34e24a41",
          "grade": true,
          "grade_id": "cell-d99dae457ea5bde6",
          "locked": false,
          "points": 1,
          "schema_version": 1,
          "solution": true
        },
        "id": "xwIhc0WaBhrW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "de7203182e41f55f391af5892477e89d",
          "grade": false,
          "grade_id": "cell-6607b79e73a101a9",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "8zPXOQUJBhrY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 2. Policy Gradient (8 points)"
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "951b88e9cd8396d088d3f80e6da9690c",
          "grade": false,
          "grade_id": "cell-083fe71da94aa7aa",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "ZJcvp_hsBhra",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "So we have spent a lot of time working on *value based* methods. We will now switch to *policy based* methods, i.e. learn a policy directly rather than learn a value function from which the policy follows. Mention two advantages of using a policy based method."
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "a5c1f505cb22eca6eb3b8213ff23e60f",
          "grade": true,
          "grade_id": "cell-134510705650d5ac",
          "locked": false,
          "points": 2,
          "schema_version": 1,
          "solution": true
        },
        "id": "ED2jct3aBhrb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The main benefits come from the fact that you can learn policy directly which makes the approach much more flexible.\n",
        "Namely,\n",
        "1.   Value based methods can't directly learn stochastic optimal policy as they have to base it on the value function, which doesn't give explicit stochasticity, while policy based methods can directly output stochastic optimal policy.\n",
        "2.  Policy based methods allow us to incorporate prior knowledge about the expected form of the policy into the learning algorithm directly. This way we can expect the system to perform better as it will \n",
        "3. The last point is that we can approximate continuous policies with policy based methods, while this is impossible with value based methods. \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "174629c02b62968e23fa6088c4d5763b",
          "grade": false,
          "grade_id": "cell-76a10fe31897025f",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "OZVXY8JgBhre",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.1 Policy Network"
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "2bc16b45e6145226b8a6f5117003b7f5",
          "grade": false,
          "grade_id": "cell-34f0712f792bbcca",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "xJywTym0Bhri",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In order to do so, we will implement a Policy network. Although in general this does not have to be the case, we will use an architecture very similar to the Q-network (two layers with ReLU activation for the hidden layer). Since we have discrete actions, our model will output one value per action, where each value represents the (normalized!) log-probability of selecting that action. *Use the (log-)softmax activation function.*"
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "155baf230fd6deb5f6ccf93138fa3419",
          "grade": false,
          "grade_id": "cell-6a31440f9477f963",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "A_rJN8gNBhrk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class PolicyNetwork(nn.Module):\n",
        "    \n",
        "    def __init__(self, num_hidden=128):\n",
        "        nn.Module.__init__(self)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(4, num_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(num_hidden, 2),\n",
        "            nn.LogSoftmax(dim = -1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.mlp(x)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "3cb94e04b03fa4b663bcf38a96ef656d",
          "grade": true,
          "grade_id": "cell-9d280fe6520edc91",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "id": "esntmFFnBhrq",
        "colab_type": "code",
        "outputId": "1ce0206b-ba69-452f-ae7d-4bb54c9ed559",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "# Let's instantiate and test if it works\n",
        "num_hidden = 128\n",
        "torch.manual_seed(1234)\n",
        "model = PolicyNetwork(num_hidden)\n",
        "\n",
        "x = torch.rand(10, 4)\n",
        "\n",
        "log_p = model(x)\n",
        "\n",
        "# Does the outcome make sense?\n",
        "print(log_p.exp())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.4578, 0.5422],\n",
            "        [0.4657, 0.5343],\n",
            "        [0.4563, 0.5437],\n",
            "        [0.4634, 0.5366],\n",
            "        [0.4564, 0.5436],\n",
            "        [0.4725, 0.5275],\n",
            "        [0.4769, 0.5231],\n",
            "        [0.4834, 0.5166],\n",
            "        [0.4797, 0.5203],\n",
            "        [0.4618, 0.5382]], grad_fn=<ExpBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "619c714e930c0d167304597d188f229b",
          "grade": false,
          "grade_id": "cell-35294ca4eda15b11",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "BRTfIvDpBhru",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.2 Monte Carlo REINFORCE"
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "93ed9cbcf70541f5a04709ee89a16e78",
          "grade": false,
          "grade_id": "cell-44f33e587542974d",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "TfQAtEWABhrw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we will implement the *Monte Carlo* policy gradient algorithm. Remember from lab 1 that this means that we will estimate returns for states by sample episodes. Compared to DQN, this means that we do *not* perform an update step at every environment step, but only at the end of each episode. This means that we should generate an episode of data, compute the REINFORCE loss (which requires computing the returns) and then perform a gradient step.\n",
        "\n",
        "To help you, we already implemented a few functions that you can (but do not have to) use.\n",
        "\n",
        "* You can use `torch.multinomial` to sample from a categorical distribution.\n",
        "* The REINFORCE loss is defined as $- \\sum_t \\log \\pi_\\theta(a_t|s_t) G_t$, which means that you should compute the (discounted) return $G_t$ for all $t$. Make sure that you do this in **linear time**, otherwise your algorithm will be very slow! Note the - (minus) since you want to maximize return while you want to minimize the loss.\n",
        "* Importantly, you should **normalize the returns** (not the rewards!, e.g. subtract mean and divide by standard deviation within the episode) before computing the loss, or your estimator will have very high variance."
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "3b2c75181678fed25fcc7c8b39bb7de3",
          "grade": true,
          "grade_id": "cell-3f6e32c4931392bf",
          "locked": false,
          "points": 5,
          "schema_version": 1,
          "solution": true
        },
        "id": "biDJx3CCBhrx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.distributions import Categorical\n",
        "import random\n",
        "\n",
        "def select_action(model, state):\n",
        "  # Samples an action according to the probability distribution induced by the model\n",
        "  # Also returns the log_probability\n",
        "  # YOUR CODE HERE\n",
        "  log_p = model(torch.tensor(state).float())\n",
        "  probs = Categorical(torch.exp(log_p))\n",
        "  action = probs.sample()\n",
        "  return action, log_p[action]\n",
        "\n",
        "def run_episode(env, model):\n",
        "  episode = []\n",
        "  done = False\n",
        "  state = env.reset()\n",
        "  single_transition = []\n",
        "  while not done:\n",
        "    previous_state = state\n",
        "    action, log_p = select_action(model, state)\n",
        "    state, reward, done, _ = env.step(action.item())\n",
        "    episode.append((previous_state, log_p, reward))\n",
        "  return episode\n",
        "\n",
        "def compute_reinforce_loss(episode, discount_factor):\n",
        "    # Compute the reinforce loss\n",
        "    # Make sure that your function runs in LINEAR TIME\n",
        "    # Don't forget to normalize your RETURNS (not rewards)\n",
        "    # Note that the rewards/returns should be maximized \n",
        "    # while the loss should be minimized so you need a - somewhere\n",
        "    \n",
        "    # YOUR CODE HERE\n",
        "    states, log_probs, rewards = zip(*episode)\n",
        "    log_probs = torch.stack(log_probs)\n",
        "    episode_return = 0.0\n",
        "    returns = []\n",
        "    for r in rewards[::-1]:\n",
        "      episode_return = r + discount_factor * episode_return\n",
        "      returns.append(episode_return)\n",
        "      \n",
        "    returns = torch.tensor(returns[::-1])  \n",
        "    returns -= torch.mean(returns)\n",
        "    returns /= torch.std(returns)\n",
        "    \n",
        "    loss = -(returns * log_probs).sum()\n",
        "    return loss\n",
        "\n",
        "def run_episodes_policy_gradient(model, env, num_episodes, discount_factor, learn_rate):\n",
        "    \n",
        "    optimizer = optim.Adam(model.parameters(), learn_rate)\n",
        "    \n",
        "    episode_durations = []\n",
        "    for i in range(num_episodes):\n",
        "        \n",
        "        # YOUR CODE HERE\n",
        "        episode = run_episode(env, model)\n",
        "        loss = compute_reinforce_loss(episode, discount_factor)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "                           \n",
        "        if i % 10 == 0:\n",
        "            print(\"{2} Episode {0} finished after {1} steps\"\n",
        "                  .format(i, len(episode), '\\033[92m' if len(episode) >= 195 else '\\033[99m'))\n",
        "        episode_durations.append(len(episode))\n",
        "        \n",
        "    return episode_durations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9LhyztIpBhr0",
        "colab_type": "code",
        "outputId": "434ed62c-4bb0-486a-d45a-b0468b84916d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1147
        }
      },
      "cell_type": "code",
      "source": [
        "# Feel free to play around with the parameters!\n",
        "num_episodes = 500\n",
        "discount_factor = 0.99\n",
        "learn_rate = 0.01\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "env.seed(seed)\n",
        "\n",
        "model = PolicyNetwork(num_hidden)\n",
        "\n",
        "episode_durations_policy_gradient = run_episodes_policy_gradient(\n",
        "    model, env, num_episodes, discount_factor, learn_rate)\n",
        "\n",
        "plt.plot(smooth(episode_durations_policy_gradient, 10))\n",
        "plt.title('Episode durations per episode')\n",
        "plt.legend(['Policy gradient'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[99m Episode 0 finished after 19 steps\n",
            "\u001b[99m Episode 10 finished after 17 steps\n",
            "\u001b[99m Episode 20 finished after 27 steps\n",
            "\u001b[99m Episode 30 finished after 34 steps\n",
            "\u001b[92m Episode 40 finished after 200 steps\n",
            "\u001b[99m Episode 50 finished after 71 steps\n",
            "\u001b[99m Episode 60 finished after 57 steps\n",
            "\u001b[99m Episode 70 finished after 33 steps\n",
            "\u001b[99m Episode 80 finished after 41 steps\n",
            "\u001b[99m Episode 90 finished after 58 steps\n",
            "\u001b[92m Episode 100 finished after 200 steps\n",
            "\u001b[99m Episode 110 finished after 125 steps\n",
            "\u001b[92m Episode 120 finished after 200 steps\n",
            "\u001b[92m Episode 130 finished after 200 steps\n",
            "\u001b[92m Episode 140 finished after 200 steps\n",
            "\u001b[92m Episode 150 finished after 200 steps\n",
            "\u001b[92m Episode 160 finished after 200 steps\n",
            "\u001b[92m Episode 170 finished after 200 steps\n",
            "\u001b[92m Episode 180 finished after 200 steps\n",
            "\u001b[92m Episode 190 finished after 200 steps\n",
            "\u001b[92m Episode 200 finished after 200 steps\n",
            "\u001b[92m Episode 210 finished after 200 steps\n",
            "\u001b[92m Episode 220 finished after 200 steps\n",
            "\u001b[99m Episode 230 finished after 192 steps\n",
            "\u001b[92m Episode 240 finished after 200 steps\n",
            "\u001b[92m Episode 250 finished after 200 steps\n",
            "\u001b[92m Episode 260 finished after 200 steps\n",
            "\u001b[92m Episode 270 finished after 200 steps\n",
            "\u001b[92m Episode 280 finished after 200 steps\n",
            "\u001b[92m Episode 290 finished after 200 steps\n",
            "\u001b[92m Episode 300 finished after 200 steps\n",
            "\u001b[92m Episode 310 finished after 200 steps\n",
            "\u001b[92m Episode 320 finished after 200 steps\n",
            "\u001b[92m Episode 330 finished after 200 steps\n",
            "\u001b[92m Episode 340 finished after 200 steps\n",
            "\u001b[92m Episode 350 finished after 200 steps\n",
            "\u001b[92m Episode 360 finished after 200 steps\n",
            "\u001b[92m Episode 370 finished after 200 steps\n",
            "\u001b[92m Episode 380 finished after 200 steps\n",
            "\u001b[92m Episode 390 finished after 200 steps\n",
            "\u001b[92m Episode 400 finished after 200 steps\n",
            "\u001b[92m Episode 410 finished after 200 steps\n",
            "\u001b[92m Episode 420 finished after 200 steps\n",
            "\u001b[92m Episode 430 finished after 200 steps\n",
            "\u001b[92m Episode 440 finished after 200 steps\n",
            "\u001b[92m Episode 450 finished after 200 steps\n",
            "\u001b[92m Episode 460 finished after 200 steps\n",
            "\u001b[92m Episode 470 finished after 200 steps\n",
            "\u001b[99m Episode 480 finished after 156 steps\n",
            "\u001b[99m Episode 490 finished after 165 steps\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fe6a7bff6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEHCAYAAABRF9YCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIhbUjTEmi/x/Zg8/7Q7uocsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fe6a9c450b8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "b9fe846472bc09094ba671593c4b40b4",
          "grade": false,
          "grade_id": "cell-af9c49b396393dc0",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "7115fmuBBhr3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Actor-Critic (7 points)"
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "ff32c0931b08aa9a5719639105a7b3e5",
          "grade": false,
          "grade_id": "cell-7eabad968ce02adf",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "RHV-24ioBhr5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will now implement the basic Actor-Critic algorithm, which means that instead of using Monte Carlo returns, we will bootstrap (1-step) returns using a critic (state-value function), so $G_t = R_t + \\gamma V(s_{t+1})$. What happens at the end of the episode? Hint: you may find it useful to have a look at the `train` method for DQN.\n",
        "\n",
        "* Note that we now have to train an actor (policy) and a critic (value network).\n",
        "* We will do this using a single optimizer, which means that we have to sum the loss for the actor and the critic into a single loss term. \n",
        "* For the critic, use the `smooth_l1_loss` like with DQN.\n",
        "* For the actor, the loss should be the REINFORCE loss, but with two differences:\n",
        "    - Instead of the Monte Carlo return $G_t$, use the one step return $G_{t:t+1}$ where the critic is used to bootstrap the value of $s_{t+1}$.\n",
        "    - Instead of normalizing the returns (which can be viewed as using the average as baseline and then scaling), we will use the estimated value $V(s_t)$ as baseline.\n",
        "* **Important**: note that you cannot use `with torch.no_grad():` to compute the critic value (for the current state) since you need gradients to train the critic! However, when using the value to compute the actor loss, you do not want to get gradients of the critic parameters w.r.t. the actor loss (e.g. your target and baseline must be constant)! Therefore, use `v.detach()` on the output of the critic when it is used in the loss term for the actor, this will make sure the value(s) are treated as a constant and no gradients will be backpropagated."
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "3b649f137296d2c6e9ac367781f1b04e",
          "grade": true,
          "grade_id": "cell-5a7326fd2ab9349c",
          "locked": false,
          "points": 5,
          "schema_version": 1,
          "solution": true
        },
        "id": "w98emy0LBhr6",
        "colab_type": "code",
        "outputId": "bf3ca6e9-e05f-4233-d29c-cadae48d6b24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1839
        }
      },
      "cell_type": "code",
      "source": [
        "class ValueNetwork(nn.Module):\n",
        "    \n",
        "    def __init__(self, num_hidden=128):\n",
        "        nn.Module.__init__(self)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(4, num_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(num_hidden, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.mlp(x)\n",
        "        return out\n",
        "    \n",
        "\n",
        "def select_action(model, state):\n",
        "    # Samples an action according to the probability distribution induced by the model\n",
        "    # Also returns the log_probability\n",
        "    # YOUR CODE HERE\n",
        "    log_p = model(torch.tensor(state).float())\n",
        "    probs = Categorical(torch.exp(log_p))\n",
        "    action = probs.sample()\n",
        "    log_p = log_p[range(0, len(state)), action]\n",
        "    # action and log_p should be a 1 dimensional vector\n",
        "    n = len(state)\n",
        "    assert action.size() == (n, )\n",
        "    assert log_p.size() == (n, )\n",
        "    return action, log_p\n",
        "\n",
        "def train_actor_critic(actor, critic, optimizer, log_ps, state, reward, next_state, done, discount_factor):\n",
        "    \n",
        "    # YOUR CODE HERE\n",
        "    v_next = critic(next_state).squeeze()\n",
        "    v_cur = critic(state).squeeze()\n",
        "    \n",
        "    tgt = (reward + discount_factor * v_next - v_cur) * (~done).float()\n",
        "    error = tgt - v_cur\n",
        "    \n",
        "    value_loss = F.smooth_l1_loss(error, torch.zeros_like(error))\n",
        "    actor_loss = (-(log_ps * error.detach())).mean()\n",
        "    \n",
        "    # The loss is composed of the value_loss (for the critic) and the actor_loss\n",
        "    \n",
        "    loss = value_loss + actor_loss\n",
        "\n",
        "    # backpropagation of loss to Neural Network (PyTorch magic)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(actor.parameters(), 1)\n",
        "    torch.nn.utils.clip_grad_norm_(critic.parameters(), 1)\n",
        "    optimizer.step()\n",
        "    \n",
        "    return loss.item(), value_loss.item(), actor_loss.item()  # Returns a Python scalar, and releases history (similar to .detach())\n",
        "\n",
        "def run_episodes_actor_critic(actor, critic, envs, max_episodes, max_steps, discount_factor, actor_learn_rate, critic_learn_rate):\n",
        "    \n",
        "    # We can use a single optimizer for both the actor and the critic, even with separate learn rates\n",
        "    optimizer = optim.Adam([\n",
        "        {'params': actor.parameters(), 'lr': actor_learn_rate},\n",
        "        {'params': critic.parameters(), 'lr': critic_learn_rate}\n",
        "    ])\n",
        "    \n",
        "    episode_durations = []\n",
        "    state = torch.tensor([env.reset() for env in envs], dtype=torch.float)\n",
        "    current_episode_lengths = torch.zeros(len(envs), dtype=torch.int64)\n",
        "    step_losses = []  # Keep track of losses for plotting\n",
        "    for i in range(max_steps):\n",
        "        \n",
        "        if i % 100 == 0:\n",
        "            print(f\"Step {i}, finished {len(episode_durations)} / {num_episodes} episodes, average episode duration of last 100 episodes: {np.mean(episode_durations[-100:])}\")\n",
        "        \n",
        "        action, log_ps = select_action(actor, state)\n",
        "        next_state, reward, done, _ = zip(*[env.step(a.item()) for env, a in zip(envs, action)])\n",
        "        \n",
        "        next_state = torch.tensor(next_state, dtype=torch.float)\n",
        "        reward = torch.tensor(reward, dtype=torch.float)\n",
        "        done = torch.tensor(done, dtype=torch.uint8)  # Boolean\n",
        "        current_episode_lengths += 1\n",
        "        \n",
        "        losses = train_actor_critic(actor, critic, optimizer, log_ps, state, reward, next_state, done, discount_factor)\n",
        "        \n",
        "        step_losses.append(losses)\n",
        "        \n",
        "        # Reset envs that are done\n",
        "        next_state = torch.tensor([\n",
        "            env.reset() if d else s.tolist()\n",
        "            for env, s, d in zip(envs, next_state, done)\n",
        "        ], dtype=torch.float)\n",
        "        \n",
        "        episode_durations.extend(current_episode_lengths[done])\n",
        "        current_episode_lengths[done] = 0  # PyTorch can also work in place\n",
        "        \n",
        "        state = next_state\n",
        "        \n",
        "        # Check if we have finished sufficiently many episodes\n",
        "        if len(episode_durations) >= max_episodes:\n",
        "            break\n",
        "        \n",
        "    return episode_durations[:max_episodes], step_losses  # In case we want exactly num_episodes returned\n",
        "\n",
        "\n",
        "num_envs = 16\n",
        "max_steps = 10000\n",
        "max_episodes = 10000\n",
        "discount_factor = 0.8\n",
        "lr_actor = 1e-3\n",
        "lr_critic = 1e-3\n",
        "seed = 42\n",
        "\n",
        "actor = PolicyNetwork(num_hidden)\n",
        "critic = ValueNetwork(num_hidden)\n",
        "\n",
        "envs = [gym.envs.make(\"CartPole-v0\") for i in range(num_envs)]\n",
        "\n",
        "for i, env in enumerate(envs):\n",
        "    env.seed(seed + i)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "episode_durations, step_losses = run_episodes_actor_critic(actor, critic, envs, max_episodes, max_steps, discount_factor, lr_actor, lr_critic)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
            "  result = entry_point.load(False)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 0, finished 0 / 10000 episodes, average episode duration of last 100 episodes: nan\n",
            "Step 100, finished 98 / 10000 episodes, average episode duration of last 100 episodes: 14.857142857142858\n",
            "Step 200, finished 190 / 10000 episodes, average episode duration of last 100 episodes: 16.84\n",
            "Step 300, finished 274 / 10000 episodes, average episode duration of last 100 episodes: 18.86\n",
            "Step 400, finished 324 / 10000 episodes, average episode duration of last 100 episodes: 23.13\n",
            "Step 500, finished 369 / 10000 episodes, average episode duration of last 100 episodes: 32.59\n",
            "Step 600, finished 415 / 10000 episodes, average episode duration of last 100 episodes: 35.89\n",
            "Step 700, finished 454 / 10000 episodes, average episode duration of last 100 episodes: 36.17\n",
            "Step 800, finished 491 / 10000 episodes, average episode duration of last 100 episodes: 38.48\n",
            "Step 900, finished 524 / 10000 episodes, average episode duration of last 100 episodes: 42.28\n",
            "Step 1000, finished 557 / 10000 episodes, average episode duration of last 100 episodes: 46.44\n",
            "Step 1100, finished 590 / 10000 episodes, average episode duration of last 100 episodes: 47.55\n",
            "Step 1200, finished 613 / 10000 episodes, average episode duration of last 100 episodes: 52.11\n",
            "Step 1300, finished 639 / 10000 episodes, average episode duration of last 100 episodes: 55.96\n",
            "Step 1400, finished 658 / 10000 episodes, average episode duration of last 100 episodes: 59.86\n",
            "Step 1500, finished 672 / 10000 episodes, average episode duration of last 100 episodes: 67.92\n",
            "Step 1600, finished 688 / 10000 episodes, average episode duration of last 100 episodes: 75.61\n",
            "Step 1700, finished 699 / 10000 episodes, average episode duration of last 100 episodes: 83.54\n",
            "Step 1800, finished 711 / 10000 episodes, average episode duration of last 100 episodes: 93.22\n",
            "Step 1900, finished 726 / 10000 episodes, average episode duration of last 100 episodes: 99.74\n",
            "Step 2000, finished 737 / 10000 episodes, average episode duration of last 100 episodes: 105.39\n",
            "Step 2100, finished 752 / 10000 episodes, average episode duration of last 100 episodes: 115.56\n",
            "Step 2200, finished 764 / 10000 episodes, average episode duration of last 100 episodes: 117.42\n",
            "Step 2300, finished 776 / 10000 episodes, average episode duration of last 100 episodes: 121.89\n",
            "Step 2400, finished 790 / 10000 episodes, average episode duration of last 100 episodes: 128.29\n",
            "Step 2500, finished 796 / 10000 episodes, average episode duration of last 100 episodes: 129.48\n",
            "Step 2600, finished 807 / 10000 episodes, average episode duration of last 100 episodes: 132.36\n",
            "Step 2700, finished 816 / 10000 episodes, average episode duration of last 100 episodes: 135.43\n",
            "Step 2800, finished 827 / 10000 episodes, average episode duration of last 100 episodes: 140.33\n",
            "Step 2900, finished 840 / 10000 episodes, average episode duration of last 100 episodes: 142.96\n",
            "Step 3000, finished 852 / 10000 episodes, average episode duration of last 100 episodes: 140.94\n",
            "Step 3100, finished 863 / 10000 episodes, average episode duration of last 100 episodes: 145.72\n",
            "Step 3200, finished 870 / 10000 episodes, average episode duration of last 100 episodes: 149.23\n",
            "Step 3300, finished 881 / 10000 episodes, average episode duration of last 100 episodes: 152.6\n",
            "Step 3400, finished 888 / 10000 episodes, average episode duration of last 100 episodes: 157.37\n",
            "Step 3500, finished 901 / 10000 episodes, average episode duration of last 100 episodes: 156.39\n",
            "Step 3600, finished 915 / 10000 episodes, average episode duration of last 100 episodes: 149.09\n",
            "Step 3700, finished 922 / 10000 episodes, average episode duration of last 100 episodes: 145.18\n",
            "Step 3800, finished 932 / 10000 episodes, average episode duration of last 100 episodes: 152.44\n",
            "Step 3900, finished 940 / 10000 episodes, average episode duration of last 100 episodes: 155.92\n",
            "Step 4000, finished 950 / 10000 episodes, average episode duration of last 100 episodes: 160.88\n",
            "Step 4100, finished 960 / 10000 episodes, average episode duration of last 100 episodes: 164.93\n",
            "Step 4200, finished 971 / 10000 episodes, average episode duration of last 100 episodes: 162.29\n",
            "Step 4300, finished 978 / 10000 episodes, average episode duration of last 100 episodes: 162.58\n",
            "Step 4400, finished 987 / 10000 episodes, average episode duration of last 100 episodes: 164.75\n",
            "Step 4500, finished 997 / 10000 episodes, average episode duration of last 100 episodes: 166.59\n",
            "Step 4600, finished 1005 / 10000 episodes, average episode duration of last 100 episodes: 168.72\n",
            "Step 4700, finished 1015 / 10000 episodes, average episode duration of last 100 episodes: 175.22\n",
            "Step 4800, finished 1022 / 10000 episodes, average episode duration of last 100 episodes: 178.89\n",
            "Step 4900, finished 1031 / 10000 episodes, average episode duration of last 100 episodes: 179.28\n",
            "Step 5000, finished 1038 / 10000 episodes, average episode duration of last 100 episodes: 182.02\n",
            "Step 5100, finished 1049 / 10000 episodes, average episode duration of last 100 episodes: 182.18\n",
            "Step 5200, finished 1054 / 10000 episodes, average episode duration of last 100 episodes: 183.83\n",
            "Step 5300, finished 1065 / 10000 episodes, average episode duration of last 100 episodes: 187.63\n",
            "Step 5400, finished 1070 / 10000 episodes, average episode duration of last 100 episodes: 190.99\n",
            "Step 5500, finished 1084 / 10000 episodes, average episode duration of last 100 episodes: 187.33\n",
            "Step 5600, finished 1096 / 10000 episodes, average episode duration of last 100 episodes: 179.69\n",
            "Step 5700, finished 1116 / 10000 episodes, average episode duration of last 100 episodes: 159.65\n",
            "Step 5800, finished 1128 / 10000 episodes, average episode duration of last 100 episodes: 150.3\n",
            "Step 5900, finished 1135 / 10000 episodes, average episode duration of last 100 episodes: 147.82\n",
            "Step 6000, finished 1145 / 10000 episodes, average episode duration of last 100 episodes: 147.36\n",
            "Step 6100, finished 1156 / 10000 episodes, average episode duration of last 100 episodes: 144.05\n",
            "Step 6200, finished 1167 / 10000 episodes, average episode duration of last 100 episodes: 138.73\n",
            "Step 6300, finished 1179 / 10000 episodes, average episode duration of last 100 episodes: 131.28\n",
            "Step 6400, finished 1183 / 10000 episodes, average episode duration of last 100 episodes: 132.79\n",
            "Step 6500, finished 1195 / 10000 episodes, average episode duration of last 100 episodes: 142.46\n",
            "Step 6600, finished 1199 / 10000 episodes, average episode duration of last 100 episodes: 146.0\n",
            "Step 6700, finished 1211 / 10000 episodes, average episode duration of last 100 episodes: 160.55\n",
            "Step 6800, finished 1215 / 10000 episodes, average episode duration of last 100 episodes: 165.77\n",
            "Step 6900, finished 1227 / 10000 episodes, average episode duration of last 100 episodes: 176.64\n",
            "Step 7000, finished 1231 / 10000 episodes, average episode duration of last 100 episodes: 178.68\n",
            "Step 7100, finished 1243 / 10000 episodes, average episode duration of last 100 episodes: 181.36\n",
            "Step 7200, finished 1247 / 10000 episodes, average episode duration of last 100 episodes: 182.55\n",
            "Step 7300, finished 1259 / 10000 episodes, average episode duration of last 100 episodes: 186.37\n",
            "Step 7400, finished 1263 / 10000 episodes, average episode duration of last 100 episodes: 188.03\n",
            "Step 7500, finished 1276 / 10000 episodes, average episode duration of last 100 episodes: 196.8\n",
            "Step 7600, finished 1288 / 10000 episodes, average episode duration of last 100 episodes: 192.96\n",
            "Step 7700, finished 1292 / 10000 episodes, average episode duration of last 100 episodes: 191.05\n",
            "Step 7800, finished 1304 / 10000 episodes, average episode duration of last 100 episodes: 190.24\n",
            "Step 7900, finished 1308 / 10000 episodes, average episode duration of last 100 episodes: 190.24\n",
            "Step 8000, finished 1320 / 10000 episodes, average episode duration of last 100 episodes: 190.34\n",
            "Step 8100, finished 1324 / 10000 episodes, average episode duration of last 100 episodes: 190.35\n",
            "Step 8200, finished 1336 / 10000 episodes, average episode duration of last 100 episodes: 190.35\n",
            "Step 8300, finished 1340 / 10000 episodes, average episode duration of last 100 episodes: 190.35\n",
            "Step 8400, finished 1352 / 10000 episodes, average episode duration of last 100 episodes: 190.35\n",
            "Step 8500, finished 1356 / 10000 episodes, average episode duration of last 100 episodes: 190.35\n",
            "Step 8600, finished 1368 / 10000 episodes, average episode duration of last 100 episodes: 190.37\n",
            "Step 8700, finished 1372 / 10000 episodes, average episode duration of last 100 episodes: 190.37\n",
            "Step 8800, finished 1384 / 10000 episodes, average episode duration of last 100 episodes: 195.04\n",
            "Step 8900, finished 1388 / 10000 episodes, average episode duration of last 100 episodes: 197.28\n",
            "Step 9000, finished 1400 / 10000 episodes, average episode duration of last 100 episodes: 199.73\n",
            "Step 9100, finished 1404 / 10000 episodes, average episode duration of last 100 episodes: 199.96\n",
            "Step 9200, finished 1418 / 10000 episodes, average episode duration of last 100 episodes: 199.17\n",
            "Step 9300, finished 1423 / 10000 episodes, average episode duration of last 100 episodes: 196.38\n",
            "Step 9400, finished 1434 / 10000 episodes, average episode duration of last 100 episodes: 196.33\n",
            "Step 9500, finished 1439 / 10000 episodes, average episode duration of last 100 episodes: 196.33\n",
            "Step 9600, finished 1451 / 10000 episodes, average episode duration of last 100 episodes: 194.99\n",
            "Step 9700, finished 1456 / 10000 episodes, average episode duration of last 100 episodes: 193.55\n",
            "Step 9800, finished 1467 / 10000 episodes, average episode duration of last 100 episodes: 193.55\n",
            "Step 9900, finished 1472 / 10000 episodes, average episode duration of last 100 episodes: 193.55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pEvlFwc3Bhr-",
        "colab_type": "code",
        "outputId": "030829ed-037f-45a2-d12c-8c168bd60510",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(smooth(episode_durations, 100))\n",
        "plt.title('Episode durations')\n",
        "plt.show()\n",
        "loss, v_loss, a_loss = zip(*step_losses)\n",
        "\n",
        "plt.plot(smooth(v_loss, 100))\n",
        "plt.title('Value loss')\n",
        "plt.show()\n",
        "plt.plot(smooth(a_loss, 100))\n",
        "plt.title('Actor loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEHCAYAAABRF9YCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fe6a822af60>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEHCAYAAABLKzaMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fe6a80de1d0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEHCAYAAABGNUbLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/iIiOUjhLyKSg/4/tkT9NWri4w4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fe6a7dd3b70>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "de8c4cba2ebd1a8bba2236f92a0b550c",
          "grade": false,
          "grade_id": "cell-8d15d4c9c0310bec",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "Fdjak6jdBhsB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "What is the difficulty of training AC algorithms? What could you try to do to overcome these difficulties? Hint: look at some online implementations."
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "1e51e82a7730101dfd07b2f0e470d1b4",
          "grade": true,
          "grade_id": "cell-f68c6134a9df40b9",
          "locked": false,
          "points": 2,
          "schema_version": 1,
          "solution": true
        },
        "id": "IKxePk9wBhsC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The main issue for the training of the AC algorithm is that we use function approximators for estimating both policy and action-value functions. \n",
        "\n",
        "As the Critic computes the value of taking action at the specific state and then the Actor updates its policy parameters using this value, if any of the agents doesn't perform well, this directly affects the other agent. \n",
        "\n",
        "Therefore, the algorithm might diverge as poor performance of one of them will make the other peform worse and this can accumulate up until the divergence.  \n",
        "\n",
        "Potential way of avoiding those issues would be to pre-train critic using $\\epsilon$-greedy policy and then include actor into training process. This way actor would already have better estimates of the action-state values and will be able to learn better policy which in turn will help critic perform better."
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "5947c1e643f533003715ae8da659af9e",
          "grade": false,
          "grade_id": "cell-ad1138b69e6728a0",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "gPOKwd9LBhsD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Deep Reinforcement Learning (5 bonus points)\n",
        "Note that so far we used the state variables as input. However, the true power of Deep Learning is that we can directly learn from raw inputs, e.g. we can learn to balance the cart pole *by just looking at the screen*. This probably means that you need a deep(er) (convolutional) network, as well as tweaking some parameters, running for more iterations (perhaps on GPU) and do other tricks to stabilize learning. Can you get this to work? This will earn you bonus points!\n",
        "\n",
        "Hints:\n",
        "* You may want to use [Google Colab](https://colab.research.google.com/) such that you can benefit from GPU acceleration.\n",
        "* Even if you don't use Colab, save the weights of your final model and load it in the code here (see example below). Hand in the model file with the .ipynb in a .zip. We likely won't be able to run your training code during grading!\n",
        "* To run the code below, you need to install `torchvision`, for this uncomment the two lines in the cell below or run the command in a terminal. Note: you may need to restart the terminal after installing.\n",
        "* Preprocessing is already done for you, and the observation is the difference between two consequtive frames such that the model can 'see' (angular) speed from a single image. Now do you see why we (sometimes) use the word observation (and not state)?"
      ]
    },
    {
      "metadata": {
        "id": "1bWaim2aBhsF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# %%bash\n",
        "# conda install torchvision -c pytorch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "f660e1484fe2bf60d66467326eacb1ba",
          "grade": false,
          "grade_id": "cell-9c9dfa80827c5680",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "lCHmEyOMBhsS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "resize = T.Compose([T.ToPILImage(),\n",
        "                    T.Resize(40, interpolation=Image.CUBIC),\n",
        "                    T.ToTensor()])\n",
        "\n",
        "class CartPoleRawEnv(gym.Env):\n",
        "    \n",
        "    def __init__(self, *args, **kwargs):\n",
        "        self._env = gym.make('CartPole-v0', *args, **kwargs)  #.unwrapped\n",
        "        self.action_space = self._env.action_space\n",
        "        screen_height, screen_width = 40, 80  # TODO\n",
        "        self.observation_space = gym.spaces.Box(\n",
        "            low=0, high=255, \n",
        "            shape=(screen_height, screen_width, 3), dtype=np.uint8)\n",
        "    \n",
        "    def seed(self, seed=None):\n",
        "        return self._env.seed(seed)\n",
        "    \n",
        "    def reset(self):\n",
        "        s = self._env.reset()\n",
        "        self.prev_screen = self.screen = self.get_screen()\n",
        "        return self._get_observation()\n",
        "    \n",
        "    def step(self, action):\n",
        "        s, r, done, info = self._env.step(action)\n",
        "        self.prev_screen = self.screen\n",
        "        self.screen = self.get_screen()\n",
        "        return self._get_observation(), r, done, info\n",
        "    \n",
        "    def _get_observation(self):\n",
        "        return self.screen - self.prev_screen\n",
        "    \n",
        "    def _get_cart_location(self, screen_width):\n",
        "        _env = self._env.unwrapped\n",
        "        world_width = _env.x_threshold * 2\n",
        "        scale = screen_width / world_width\n",
        "        return int(_env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
        "\n",
        "    def get_screen(self):\n",
        "        screen = self._env.unwrapped.render(mode='rgb_array').transpose(\n",
        "            (2, 0, 1))  # transpose into torch order (CHW)\n",
        "        # Strip off the top and bottom of the screen\n",
        "        _, screen_height, screen_width = screen.shape\n",
        "        screen = screen[:, screen_height * 4 // 10:screen_height * 8 // 10]\n",
        "        view_width = screen_height * 8 // 10\n",
        "        cart_location = self._get_cart_location(screen_width)\n",
        "        if cart_location < view_width // 2:\n",
        "            slice_range = slice(view_width)\n",
        "        elif cart_location > (screen_width - view_width // 2):\n",
        "            slice_range = slice(-view_width, None)\n",
        "        else:\n",
        "            slice_range = slice(cart_location - view_width // 2,\n",
        "                                cart_location + view_width // 2)\n",
        "        # Strip off the edges, so that we have a square image centered on a cart\n",
        "        screen = screen[:, :, slice_range]\n",
        "        # Convert to float, rescare, convert to torch tensor\n",
        "        # (this doesn't require a copy)\n",
        "        screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
        "        screen = torch.from_numpy(screen)\n",
        "        # Resize, and add a batch dimension (BCHW)\n",
        "        #return screen.unsqueeze(0).to(device)\n",
        "        return resize(screen).unsqueeze(0)\n",
        "    \n",
        "    def close(self):\n",
        "        return self._env.close()\n",
        "\n",
        "raw_env = CartPoleRawEnv()\n",
        "s = raw_env.reset()\n",
        "\n",
        "# \n",
        "s, r, done, _ = raw_env.step(env.action_space.sample())\n",
        "\n",
        "raw_env.reset()\n",
        "plt.figure()\n",
        "plt.imshow(raw_env.get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
        "           interpolation='none')\n",
        "plt.title('Example extracted screen')\n",
        "plt.show()\n",
        "\n",
        "# Observations are (-1, 1) while we need to plot (0, 1) so show (rgb + 1) / 2\n",
        "plt.figure()\n",
        "plt.imshow((s.cpu().squeeze(0).permute(1, 2, 0).numpy() + 1) / 2,\n",
        "           interpolation='none')\n",
        "plt.title('Example observation')\n",
        "plt.show()\n",
        "raw_env.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B-4k-695BhsY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Maybe you should make it a bit deeper?\n",
        "class DeepPolicy(nn.Module):\n",
        "    def __init__(self):\n",
        "        nn.Module.__init__(self)\n",
        "        self.l1 = nn.Linear(40 * 80 * 3, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Flatten\n",
        "        return F.log_softmax(self.l1(x.view(x.size(0), -1)), -1)\n",
        "    \n",
        "policy = DeepPolicy()\n",
        "filename = 'weights.pt'\n",
        "\n",
        "if os.path.isfile(filename):\n",
        "    print(f\"Loading weights from {filename}\")\n",
        "    weights = torch.load(filename)\n",
        "    \n",
        "    policy.load_state_dict(weights['policy'])\n",
        "    \n",
        "else:\n",
        "    # Train\n",
        "    \n",
        "    ### TODO some training here, maybe? Or run this on a different machine?\n",
        "    torch.manual_seed(42)\n",
        "    \n",
        "    print(f\"Saving weights to {filename}\")\n",
        "    torch.save({\n",
        "        # You can add more here if you need, e.g. critic\n",
        "        'policy': policy.state_dict()  # Always save weights rather than objects\n",
        "    },\n",
        "    filename)\n",
        "    \n",
        "def bonus_get_action(x):\n",
        "    return policy(x).exp().multinomial(1)[:, 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "b800bfb91f987f14e0c35bc0c41d538b",
          "grade": true,
          "grade_id": "cell-0d7bd58a23fdfabb",
          "locked": true,
          "points": 5,
          "schema_version": 1,
          "solution": false
        },
        "id": "TgDvaJexBhsf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "episode_durations = []\n",
        "for i in range(20):  # Not too many since it may take forever to render\n",
        "    test_env = CartPoleRawEnv()\n",
        "    test_env.seed(seed + i)\n",
        "    state = test_env.reset()\n",
        "    done = False\n",
        "    steps = 0\n",
        "    while not done:\n",
        "        steps += 1\n",
        "        with torch.no_grad():\n",
        "            action = bonus_get_action(state).item()\n",
        "        state, reward, done, _ = test_env.step(action)\n",
        "    episode_durations.append(steps)\n",
        "    test_env.close()\n",
        "    \n",
        "plt.plot(smooth(episode_durations, 100))\n",
        "plt.title('Episode durations')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XZBy1uROBhsn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}